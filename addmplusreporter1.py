import streamlit as st
import re
import json
import pandas as pd

# ==========================================
# 1. ìˆ˜ì‹ ì˜¤íƒ€/ë¬¸ë²• ê²€ìˆ˜ í´ë˜ìŠ¤ (ìµœìš°ì„  ì‹¤í–‰)
# ==========================================
class MathFormulaInspector:
    def __init__(self):
        self.log = []

    def get_context(self, text, start, end, window=15):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def check_parentheses(self, formula, offset, full_text):
        """ê´„í˜¸ ì§ ê²€ì‚¬ (LaTeXì˜ \{, \}ëŠ” ì œì™¸í•˜ê³  êµ¬ì¡°ì  ê´„í˜¸ë§Œ ê²€ì‚¬)"""
        # LaTeXì˜ \{, \}ëŠ” ê´„í˜¸ ì§ ê²€ì‚¬ì—ì„œ ë¬´ì‹œí•˜ê¸° ìœ„í•´ ì„ì‹œë¡œ ì¹˜í™˜
        temp_formula = formula.replace(r'\{', '..').replace(r'\}', '..')
        
        stack = []
        mapping = {')': '(', '}': '{', ']': '['}
        
        for i, char in enumerate(temp_formula):
            if char in mapping.values(): # ì—¬ëŠ” ê´„í˜¸
                stack.append((char, i))
            elif char in mapping.keys(): # ë‹«ëŠ” ê´„í˜¸
                if not stack or stack[-1][0] != mapping[char]:
                    context = self.get_context(full_text, offset+i, offset+i+1)
                    self.log.append({
                        "ìœ í˜•": "ê´„í˜¸ ì˜¤ë¥˜",
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": f"${formula}$",
                        "ë‚´ìš©": f"ë‹«ëŠ” ê´„í˜¸ '{char}'ì˜ ì§ì´ ë§ì§€ ì•ŠìŒ"
                    })
                    if stack: stack.pop()
                else:
                    stack.pop()
        
        if stack:
            for char, i in stack:
                context = self.get_context(full_text, offset+i, offset+i+1)
                self.log.append({
                    "ìœ í˜•": "ê´„í˜¸ ì˜¤ë¥˜",
                    "ë¬¸ë§¥": context,
                    "ëŒ€ìƒ": f"${formula}$",
                    "ë‚´ìš©": f"ì—¬ëŠ” ê´„í˜¸ '{char}'ê°€ ë‹«íˆì§€ ì•ŠìŒ"
                })

    def check_bad_patterns(self, formula, offset, full_text):
        """ê¸ˆì§€ëœ íŒ¨í„´ ê²€ì‚¬"""
        # 1. ê³±í•˜ê¸° ê¸°í˜¸ * ì‚¬ìš©
        if re.search(r'\d\s*\*\s*\d', formula):
            self.log.append({
                "ìœ í˜•": "í‘œê¸° ì˜¤ë¥˜",
                "ë¬¸ë§¥": self.get_context(full_text, offset, offset+len(formula)),
                "ëŒ€ìƒ": f"${formula}$",
                "ë‚´ìš©": "ê³±í•˜ê¸° ê¸°í˜¸ '*' ì‚¬ìš©ë¨ ($\\times$ ê¶Œì¥)"
            })
        
        # 2. ë¶€ë“±í˜¸ <=, >= ì‚¬ìš©
        if '<=' in formula or '>=' in formula:
             self.log.append({
                "ìœ í˜•": "í‘œê¸° ì˜¤ë¥˜",
                "ë¬¸ë§¥": self.get_context(full_text, offset, offset+len(formula)),
                "ëŒ€ìƒ": f"${formula}$",
                "ë‚´ìš©": "ë¶€ë“±í˜¸ '<=', '>=' ì‚¬ìš©ë¨ ($\\le, \\ge$ ê¶Œì¥)"
            })
             
        # 3. \frac ì¸ì ëˆ„ë½ ì˜ì‹¬
        if '\\frac' in formula and not re.search(r'\\frac\s*\{', formula):
             self.log.append({
                "ìœ í˜•": "ë¬¸ë²• ì˜¤ë¥˜",
                "ë¬¸ë§¥": self.get_context(full_text, offset, offset+len(formula)),
                "ëŒ€ìƒ": f"${formula}$",
                "ë‚´ìš©": "\\frac ëª…ë ¹ì–´ ì¸ì ëˆ„ë½ ì˜ì‹¬"
            })

    def check_arithmetic(self, text):
        """ë‹¨ìˆœ ì •ìˆ˜ ì‚¬ì¹™ì—°ì‚° ê²€ì¦ (ì „ì²´ í…ìŠ¤íŠ¸ ëŒ€ìƒ)"""
        # ì˜ˆ: 12 + 3 = 15 (ê³µë°± í—ˆìš©, ì •ìˆ˜ë§Œ)
        # ë³´ì•ˆì„ ìœ„í•´ ì •ê·œì‹ìœ¼ë¡œ ì—„ê²©í•˜ê²Œ ìˆ«ìì™€ ì—°ì‚°ìë§Œ ì¶”ì¶œ
        equation_pattern = re.compile(r'(?<![\.\d])(\d+[\s\+\-\*\/]+\d+\s*=\s*\d+)(?![\.\d])')
        matches = equation_pattern.finditer(text)
        
        for m in matches:
            eq_str = m.group(1)
            try:
                lhs, rhs = eq_str.split('=')
                # eval ì‚¬ìš© ì „ ì•ˆì „ì¥ì¹˜: ìˆ«ì, ê³µë°±, ì—°ì‚°ìë§Œ ìˆëŠ”ì§€ ì¬í™•ì¸
                if not re.match(r'^[\d\s\+\-\*\/]+$', lhs): continue
                
                calculated = eval(lhs)
                target = int(rhs)
                
                if calculated != target:
                    self.log.append({
                        "ìœ í˜•": "ê³„ì‚° ì˜¤ë¥˜",
                        "ë¬¸ë§¥": self.get_context(text, m.start(), m.end()),
                        "ëŒ€ìƒ": eq_str,
                        "ë‚´ìš©": f"ê³„ì‚° ë¶ˆì¼ì¹˜ (ì¢Œë³€ ê²°ê³¼: {calculated})"
                    })
            except:
                pass # 0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë“± ì˜ˆì™¸ ë¬´ì‹œ

    def run(self, text):
        self.log = []
        
        # 1. LaTeX ìˆ˜ì‹ ë‚´ë¶€ ê²€ì‚¬ ($...$)
        latex_pattern = re.compile(r'\$([^\$]+)\$')
        for m in latex_pattern.finditer(text):
            formula = m.group(1)
            start_idx = m.start()
            
            self.check_parentheses(formula, start_idx, text)
            self.check_bad_patterns(formula, start_idx, text)
            
        # 2. ì „ì²´ í…ìŠ¤íŠ¸ ëŒ€ìƒ ì‚°ìˆ  ì—°ì‚° ê²€ì‚¬
        self.check_arithmetic(text)
        
        return self.log

# ==========================================
# 2. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘ êµì • í´ë˜ìŠ¤
# ==========================================
class JosaCorrector:
    def __init__(self):
        self.log = []
        self.batchim_dict = self._init_batchim_dict()
        self.unit_batchim_dict = self._init_unit_batchim_dict()
        self.particle_pairs = self._init_particle_pairs()
        
        self.protected_words = [
            'ì´ë‹¤', 'ì…ë‹ˆë‹¤', 'ì´ë¯€ë¡œ', 'ì´ë©°', 'ì´ê³ ', 'ì´ë‚˜', 'ì´ë©´ì„œ', 'ì´ì§€ë§Œ', 'ì´ì–´ì„œ',
            'ì´ë•Œ', 'ì´ì–´ì•¼', 'ê°€ì§€',
            'ì´ë©´', # [ë³´í˜¸] ì‰¼í‘œ ë’¤ 'ì´ë©´' ìœ ì§€
            'ì´ìƒ', 'ì´í•˜', 'ì´ë‚´', 'ì´ì™¸', 'ë¯¸ë§Œ', 'ì´ˆê³¼',
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ìœ¼ë¯€ë¡œ', 'ì´ì–´ì§„', 'ì´ë£¨ì–´ì§„', 'ì´ë£¨ëŠ”', 'ì´ë™', 'ì´ìš©',
            'ì—†ëŠ”', 'ìˆëŠ”', 'ì—†ê³ ', 'ìˆê³ ', 'ì—†ì´', 'ìˆì–´', 'ì—†ì–´'
        ]

    def _init_batchim_dict(self):
        d = {
            '0': True, '1': True, '3': True, '6': True, '7': True, '8': True, '10': True,
            'l': True, 'm': True, 'n': True, 'r': True, 
            'L': True, 'M': True, 'N': True, 'R': True,
            'ì œê³±': True, 'ì—¬ì§‘í•©': True, 'ë°”': False
        }
        for c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…": d[c] = True
        for ch in '2459AaBbCcDdEeFfGgHhIiJjKkOoPpQqSsTtUuVvWwXxeYyZz':
            if ch not in d: d[ch] = False
        return d

    def _init_unit_batchim_dict(self):
        return {
            'm': False, 'cm': False, 'mm': False, 'km': False,
            'g': True, 'kg': True, 'mg': True,
            'l': False, 'L': False, 'mL': False,
            'A': False, 'V': False, 'W': False, 'Hz': False,
            'deg': False, 'degree': False
        }

    def _init_particle_pairs(self):
        return [
            ('ì´ë‹¤', 'ì´ë‹¤'), ('ì…ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤'),
            ('ì´ë¯€ë¡œ', 'ì´ë¯€ë¡œ'), ('ì´ë©°', 'ì´ë©°'), ('ì´ê³ ', 'ì´ê³ '), ('ì´ë‚˜', 'ì´ë‚˜'),
            ('ì´ë©´ì„œ', 'ì´ë©´ì„œ'), ('ì´ì§€ë§Œ', 'ì´ì§€ë§Œ'), ('ì´ì–´ì„œ', 'ì´ì–´ì„œ'),
            ('ì´ë•Œ', 'ì´ë•Œ'), ('ì´ì–´ì•¼ í•˜ë¯€ë¡œ', 'ì´ì–´ì•¼ í•˜ë¯€ë¡œ'),
            ('ê°€ì§€', 'ê°€ì§€'),
            ('ì´ë¼ì„œ', 'ë¼ì„œ'), ('ì´ë¼ê³ ', 'ë¼ê³ '), ('ì´ë¼', 'ë¼'), ('ì´ë©´', 'ë©´'), 
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ'), ('ì„', 'ìš¸')
        ]

    def get_balanced(self, text, start_idx):
        if start_idx == -1 or start_idx >= len(text): return None, start_idx
        count = 0
        for i in range(start_idx, len(text)):
            if text[i] == '{': count += 1
            elif text[i] == '}': count -= 1
            if count == 0: return text[start_idx+1:i], i + 1
        return None, start_idx

    def simplify_formula(self, latex_str):
        current = latex_str.replace(r'\left', '').replace(r'\right', '')
        prev_str = ""
        while prev_str != current:
            prev_str = current
            if '\\frac' in current:
                idx = current.find('\\frac')
                num, end_num = self.get_balanced(current, current.find('{', idx))
                _, end_den = self.get_balanced(current, current.find('{', end_num))
                if num is not None:
                    current = current[:idx] + num + current[end_den:]
                    continue
            if '\\sqrt' in current:
                idx = current.find('\\sqrt')
                if idx + 5 < len(current) and current[idx+5] == '[':
                    close_bracket = current.find(']', idx)
                    if close_bracket != -1:
                        current = current[:idx+5] + current[close_bracket+1:]
                        continue
            stripped = current.strip()
            if stripped.startswith('{') and stripped.endswith('}'):
                content, end = self.get_balanced(stripped, 0)
                if end == len(stripped):
                    current = content
                    continue
        return current

    def find_target(self, formula_str):
        simplified = self.simplify_formula(formula_str)
        clean = re.sub(r'\s+', '', simplified)
        masked_text = clean
        braces_content = []
        while True:
            start = masked_text.find('{')
            if start == -1: break
            content, end_idx = self.get_balanced(masked_text, start)
            if content is None: break
            placeholder = f"@BRACE{len(braces_content)}@"
            braces_content.append(content)
            masked_text = masked_text[:start] + placeholder + masked_text[end_idx:]

        split_pattern = (r'=|\\approx|\\ne|>|<|\\ge|\\le|\\times|\\div|'
                         r'(?<!\^)\+|(?<!\^)-|\\cdot|'
                         r'\\cap|\\cup|\\setminus|\\subset|\\subseteq|\\in|\\ni')
        parts = re.split(split_pattern, masked_text)
        final_term = parts[-1] if parts else masked_text

        while "@BRACE" in final_term:
            for i, content in enumerate(braces_content):
                placeholder = f"@BRACE{i}@"
                if placeholder in final_term:
                    final_term = final_term.replace(placeholder, "{" + content + "}")

        if r'\degree' in final_term or r'^\circ' in final_term: return "ë„"
        if "^" in final_term:
            if "C" in final_term: return "ì—¬ì§‘í•©"
            base_part = final_term.split('^')[0]
            mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', base_part)
            if mathrm_match:
                unit_content = mathrm_match.group(1)
                if unit_content in ['m', 'cm', 'mm', 'km']: return "ë¯¸í„°"
            return "ì œê³±"

        mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', final_term)
        if mathrm_match: return f"UNIT:{mathrm_match.group(1)}"

        if final_term.endswith(')'):
             m = re.search(r'([ê°€-í£a-zA-Z0-9])\)+$', final_term)
             if m: return m.group(1)

        text_only = re.sub(r'\\[a-zA-Z]+|[{}]|[()\[\]]|[\.,]', '', final_term)
        text_only = text_only.replace('\\', '').strip() 
        return text_only[-1] if text_only else ""

    def get_correct_p(self, target, original_p):
        for word in self.protected_words:
            if original_p.startswith(word): return original_p

        if not target.startswith("UNIT:") and len(target) == 1 and re.match(r'[a-zA-Z0-9]', target):
            is_noun_mask = False
            if original_p.startswith('ê°€ë©´'):
                after_mask = original_p[2:]
                if after_mask and after_mask[0] in ['ì„', 'ì´', 'ì€', 'ê³¼', 'ì˜', 'ë¡œ']: is_noun_mask = True
                if not is_noun_mask and original_p.startswith(('ì´ë©´', 'ë©´', 'ê°€ë©´')):
                    suffix = original_p[2:] if original_p.startswith('ê°€ë©´') else original_p[len('ì´ë©´' if original_p.startswith('ì´ë©´') else 'ë©´'):]
                    return 'ì´ë©´' + suffix

        has_batchim = False
        if target.startswith("UNIT:"):
            real_unit = target.split(":")[1]
            has_batchim = self.unit_batchim_dict.get(real_unit, False)
        elif target == "ë¯¸í„°": has_batchim = False
        else:
            if target in self.batchim_dict: has_batchim = self.batchim_dict[target]
            elif len(target) == 1 and 'ê°€' <= target <= 'í£': has_batchim = (ord(target) - 0xAC00) % 28 > 0
            elif len(target) > 1:
                last = target[-1]
                has_batchim = (ord(last) - 0xAC00) % 28 > 0 if 'ê°€' <= last <= 'í£' else self.batchim_dict.get(last, False)
            else: has_batchim = self.batchim_dict.get(target, False)

        is_rieul = target in ['1', '7', '8', 'L', 'R', 'l', 'r', 'ã„¹']
        
        for has_b, no_b in self.particle_pairs:
            if original_p.startswith(has_b) or original_p.startswith(no_b):
                if has_b == 'ìœ¼ë¡œ':
                    stem = 'ìœ¼ë¡œ' if (has_batchim and not is_rieul) else 'ë¡œ'
                else:
                    stem = has_b if has_batchim else no_b
                return stem + original_p[len(has_b if original_p.startswith(has_b) else no_b):]
        return original_p

    def clean_latex_for_human(self, latex):
        text = re.sub(r'\\(left|right|mathrm|text|bf|it)', '', latex)
        text = text.replace('{', '').replace('}', '').replace('\\', '')
        return text.strip()

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, raw_input):
        self.log = [] 
        try:
            if isinstance(raw_input, dict): input_data = raw_input
            else: input_data = json.loads(raw_input)
            target_text = input_data.get("result", raw_input) if isinstance(input_data, dict) else str(raw_input)
        except:
            target_text = str(raw_input)

        def replacer(match):
            pre, s1, formula, s2, particle = match.groups()
            p_match = re.search(r'[ê°€-í£]+', particle)
            
            match_start = match.start()
            match_end = match.end()

            if not p_match:
                if '.' in particle:
                    new_particle = particle.replace('.', '')
                    human_readable = self.clean_latex_for_human(formula)
                    context = self.get_context(target_text, match_start, match_end)
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": human_readable,
                        "ì›ë¬¸": particle,
                        "ìˆ˜ì •": new_particle,
                        "ì‚¬ìœ ": "ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ ì œê±°"
                    })
                    return f"{pre}{s1}${formula}${s2}{new_particle}"
                return match.group(0)

            p_start = p_match.start()
            original_p = p_match.group()
            remaining_particle = particle[p_start:]
            
            for word in self.protected_words:
                if remaining_particle.startswith(word): return match.group(0)
                
            target = self.find_target(formula)
            correct_p = self.get_correct_p(target, original_p)
            
            if original_p != correct_p:
                human_readable = self.clean_latex_for_human(formula)
                context = self.get_context(target_text, match_start, match_end)
                self.log.append({
                    "ë¬¸ë§¥": context,
                    "ëŒ€ìƒ": human_readable,
                    "ì›ë¬¸": original_p,
                    "ìˆ˜ì •": correct_p,
                    "ì‚¬ìœ ": "ë°›ì¹¨ í˜¸ì‘ ì˜¤ë¥˜"
                })

            return f"{pre}{s1}${formula}${s2}{particle[:p_start]}{correct_p}{particle[p_match.end():]}"

        pattern = r'([^$]*?)(\s*)\$([^\$]+)\$(\s*)([\s,]*[ê°€-í£\s\.\?\!]+)'
        fixed_text = re.sub(pattern, replacer, target_text, flags=re.DOTALL)
        return fixed_text, self.log

# ==========================================
# 3. í•œê¸€ ë§ì¶¤ë²•/ì˜¤íƒ€/ì¡°ì‚¬ êµì • í´ë˜ìŠ¤
# ==========================================
class SpellingCorrector:
    def __init__(self):
        self.log = []
        self.typo_dict = {
            "ìµœëŒ€ê°’": "ìµœëŒ“ê°’", "ìµœì†Œê°’": "ìµœì†Ÿê°’", "ê·¹ëŒ€ê°’": "ê·¹ëŒ“ê°’", "ê·¹ì†Œê°’": "ê·¹ì†Ÿê°’",
            "ì ˆëŒ€ê°’": "ì ˆëŒ“ê°’", "ê·¼ì‚¬ê°’": "ê·¼ì‚¿ê°’", "ëŒ€í‘œê°’": "ëŒ€í‘¯ê°’", "í•¨ìˆ˜ê°’": "í•¨ìˆ«ê°’",
            "ê¼­ì§€ì ": "ê¼­ì§“ì ", "ì´›ì ": "ì´ˆì ", "ê°¯ìˆ˜": "ê°œìˆ˜", "ë‚˜ëˆ„ê¸°": "ë‚˜ëˆ—ì…ˆ",
            "ì•Šë˜": "ì•ˆ ë˜", "ì•Šë¼": "ì•ˆ ë¼", "ì•Šëœë‹¤": "ì•ˆ ëœë‹¤", "ë¬¸ì•ˆ": "ë¬´ë‚œ",
            "ê¸ˆìƒˆ": "ê¸ˆì„¸", "ì—­í™œ": "ì—­í• ", "ì œì‘ë…„": "ì¬ì‘ë…„", "ì–´ë–»í•´": "ì–´ë–¡í•´",
            "ëª‡ì¼": "ë©°ì¹ ", "ë“¤ì–´ë‚˜ë‹¤": "ë“œëŸ¬ë‚˜ë‹¤", "ê°€ë¥´í‚¤ë‹¤": "ê°€ë¦¬í‚¤ë‹¤", "ë§ì¶”ë‹¤": "ë§íˆë‹¤"
        }
        self.korean_particle_pairs = [
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ')
        ]
        
        self.exceptions = {
            'ì¦ê°€', 'ì¶”ê°€', 'ê²°ê³¼', 'íš¨ê³¼', 'ì´ˆê³¼', 'êµê³¼', 'ë¶€ê³¼', 'ì‚¬ê³¼', 'íˆ¬ê³¼',
            'í‰ê°€', 'ì›ê°€', 'ì •ê°€', 'ë‹¨ê°€', 'ì‹œê°€',
            'ì‚¬ì´', 'ì°¨ì´', 'ë‚˜ì´', 'ì•„ì´', 'ì˜¤ì´', 'ë†€ì´',
            'ê²½ë¡œ', 'ì§„ë¡œ', 'ì„ ë¡œ', 'í•­ë¡œ',
            'ì—†ëŠ”', 'ìˆëŠ”', 'ê°–ëŠ”', 'ë§ëŠ”', 'ë§¡ëŠ”', 'ì›ƒëŠ”', 'ì”»ëŠ”', 'ê¹ëŠ”', 'ë³¶ëŠ”', 'ì•ŠëŠ”',
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ì–´ì„œ', 'ê¹Šì€', 'ë†’ì€', 'ì‘ì€', 'ì¢ì€',
            'ì¸ê°€', 'ëŠ”ê°€', 'ì€ê°€', 'ë˜ê°€', 'ë‚˜', 'ê°€' 
        }

    def has_batchim(self, char):
        if 'ê°€' <= char <= 'í£':
            return (ord(char) - 0xAC00) % 28 > 0
        return False

    def is_rieul_batchim(self, char):
        if 'ê°€' <= char <= 'í£':
            return (ord(char) - 0xAC00) % 28 == 8
        return False

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, text):
        self.log = []
        parts = re.split(r'(\$[^\$]+\$)', text)
        final_parts = []
        
        for i, part in enumerate(parts):
            if i % 2 == 1: 
                final_parts.append(part)
                continue
            
            current_text = part
            
            for wrong, correct in self.typo_dict.items():
                if wrong in current_text:
                    for m in re.finditer(re.escape(wrong), current_text):
                        context = self.get_context(current_text, m.start(), m.end())
                        self.log.append({
                            "ë¬¸ë§¥": context,
                            "ëŒ€ìƒ": wrong,
                            "ì›ë¬¸": wrong,
                            "ìˆ˜ì •": correct,
                            "ì‚¬ìœ ": "ë§ì¶¤ë²•/í‘œì¤€ì–´ ì˜¤ë¥˜"
                        })
                    current_text = current_text.replace(wrong, correct)
            
            pattern = r'([ê°€-í£ã‰ -ã‰­])(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€|ìœ¼ë¡œ|ë¡œ)(?![ê°€-í£])'
            
            def josa_replacer(match):
                full_word = match.group(0)
                if full_word in self.exceptions:
                    return full_word
                
                noun_char = match.group(1)
                josa = match.group(2)
                
                if 'ê°€' <= noun_char <= 'í£':
                    has_bat = self.has_batchim(noun_char)
                    is_rieul = self.is_rieul_batchim(noun_char)
                else: 
                    has_bat = True
                    is_rieul = (noun_char == 'ã‰£')

                correct_josa = josa
                for bat_o, bat_x in self.korean_particle_pairs:
                    if josa == bat_o or josa == bat_x:
                        if bat_o == 'ìœ¼ë¡œ':
                            if not has_bat or is_rieul: correct_josa = 'ë¡œ'
                            else: correct_josa = 'ìœ¼ë¡œ'
                        else:
                            correct_josa = bat_o if has_bat else bat_x
                        break
                
                if josa != correct_josa:
                    context = self.get_context(current_text, match.start(), match.end())
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": full_word,
                        "ì›ë¬¸": josa,
                        "ìˆ˜ì •": correct_josa,
                        "ì‚¬ìœ ": "ì¡°ì‚¬ í˜¸ì‘ ì˜¤ë¥˜"
                    })
                    return f"{noun_char}{correct_josa}"
                return match.group(0)

            current_text = re.sub(pattern, josa_replacer, current_text)
            final_parts.append(current_text)
            
        return "".join(final_parts), self.log

# ==========================================
# 4. ë©”ì¸ UI (Streamlit)
# ==========================================
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°", layout="wide")

st.title("âœ¨ ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°")
st.markdown("""
**1ë‹¨ê³„: ìˆ˜ì‹ ì˜¤ë¥˜ ê²€ì‚¬** (ê´„í˜¸, í‘œê¸°ë²•, ê³„ì‚° ì˜¤ë¥˜ë¥¼ ë¨¼ì € í™•ì¸í•©ë‹ˆë‹¤)  
**2ë‹¨ê³„: í…ìŠ¤íŠ¸ êµì •** (ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘, í•œê¸€ ë§ì¶¤ë²•ì„ êµì •í•©ë‹ˆë‹¤)
""")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ì…ë ¥ (Input)")
    input_val = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", height=600, 
                             placeholder="ì˜ˆ: $A = \{ x | x > 0 $ (ê´„í˜¸ ì˜¤ë¥˜), 3 + 5 = 9 (ê³„ì‚° ì˜¤ë¥˜)")

with col2:
    st.subheader("ê²€ìˆ˜ ë¦¬í¬íŠ¸ (Report)")
    
    if input_val:
        # [Step 1] ìˆ˜ì‹ ì˜¤íƒ€ ê²€ìˆ˜ (ì›ë³¸ í…ìŠ¤íŠ¸ ê¸°ì¤€)
        math_inspector = MathFormulaInspector()
        math_logs = math_inspector.run(input_val)
        
        # ìˆ˜ì‹ ì˜¤ë¥˜ê°€ ìˆìœ¼ë©´ ìµœìƒë‹¨ì— ê²½ê³  í‘œì‹œ
        if math_logs:
            st.error(f"ğŸš¨ ìˆ˜ì‹/ê³„ì‚° ì˜¤ë¥˜ê°€ {len(math_logs)}ê±´ ë°œê²¬ë˜ì—ˆìŠµë‹ˆë‹¤! ë¨¼ì € ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
            df_math = pd.DataFrame(math_logs)
            st.dataframe(df_math[['ìœ í˜•', 'ë¬¸ë§¥', 'ëŒ€ìƒ', 'ë‚´ìš©']], use_container_width=True, hide_index=True)
            st.markdown("---") # êµ¬ë¶„ì„ 
        
        # [Step 2] í…ìŠ¤íŠ¸ êµì • ì‹¤í–‰ (ìˆ˜ì‹ ì˜¤ë¥˜ì™€ ë¬´ê´€í•˜ê²Œ ì§„í–‰)
        # 1. ì¡°ì‚¬ êµì •
        josa_corrector = JosaCorrector()
        temp_text, josa_logs = josa_corrector.run(input_val)
        
        # 2. ë§ì¶¤ë²• êµì •
        spell_corrector = SpellingCorrector()
        final_text, spell_logs = spell_corrector.run(temp_text)
        
        # --- íƒ­ìœ¼ë¡œ ìƒì„¸ ë¦¬í¬íŠ¸ ì¶œë ¥ ---
        tab1, tab2 = st.tabs(["ğŸ” ìˆ˜ì‹ ì¡°ì‚¬ ê²€ìˆ˜", "ğŸ“ í•œê¸€/ê¸°í˜¸ ê²€ìˆ˜"])
        
        with tab1:
            if josa_logs:
                st.warning(f"ìˆ˜ì‹ ì¡°ì‚¬ ì˜¤ë¥˜: {len(josa_logs)}ê±´")
                df_josa = pd.DataFrame(josa_logs)
                st.dataframe(df_josa[['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']], use_container_width=True, hide_index=True)
            else:
                st.success("ìˆ˜ì‹ ì¡°ì‚¬ê°€ ì™„ë²½í•©ë‹ˆë‹¤.")
                
        with tab2:
            if spell_logs:
                st.warning(f"í•œê¸€/ê¸°í˜¸ ì˜¤ë¥˜: {len(spell_logs)}ê±´")
                df_spell = pd.DataFrame(spell_logs)
                st.dataframe(df_spell[['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']], use_container_width=True, hide_index=True)
            else:
                st.success("ë°œê²¬ëœ ì˜¤íƒ€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("ìµœì¢… ê²°ê³¼ë¬¼ (Result)")
        st.text_area("êµì •ëœ í…ìŠ¤íŠ¸", value=final_text, height=300)
        
        st.download_button(
            label="ğŸ’¾ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=final_text,
            file_name="corrected_result.txt",
            mime="text/plain"
        )
    else:
        st.info("ì™¼ìª½ì— ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")