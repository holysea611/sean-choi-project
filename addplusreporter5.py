import streamlit as st
import re
import json
import pandas as pd

# ==========================================
# 1. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘ êµì • í´ë˜ìŠ¤ (LaTeX ëŒ€ìƒ)
# ==========================================
class JosaCorrector:
    def __init__(self):
        self.log = []
        self.batchim_dict = self._init_batchim_dict()
        self.unit_batchim_dict = self._init_unit_batchim_dict()
        self.particle_pairs = self._init_particle_pairs()
        
        # [ìˆ˜ì •] ì¡°ì‚¬ê°€ ì•„ë‹Œ ë‹¨ì–´(ë™ì‚¬/í˜•ìš©ì‚¬ í™œìš©í˜•) ë³´í˜¸ ëª©ë¡ ëŒ€í­ ê°•í™”
        # 'ì´ì€', 'ì—†ëŠ”' ë“±ì´ ì¡°ì‚¬ë¡œ ì˜¤ì¸ë˜ì§€ ì•Šë„ë¡ ì²˜ë¦¬
        self.protected_words = [
            # ì„œìˆ ê²© ì¡°ì‚¬/ì ‘ì† ì¡°ì‚¬ ë“±
            'ì´ë‹¤', 'ì…ë‹ˆë‹¤', 'ì´ë¯€ë¡œ', 'ì´ë©°', 'ì´ê³ ', 'ì´ë‚˜', 'ì´ë©´ì„œ', 'ì´ì§€ë§Œ', 'ì´ì–´ì„œ',
            'ì´ë•Œ', 'ì´ì–´ì•¼', 'ê°€ì§€',
            # ìˆ˜ëŸ‰/ë²”ìœ„ ëª…ì‚¬
            'ì´ìƒ', 'ì´í•˜', 'ì´ë‚´', 'ì´ì™¸', 'ë¯¸ë§Œ', 'ì´ˆê³¼',
            # [ì¶”ê°€] 'ì‡ë‹¤', 'ìˆë‹¤', 'ì—†ë‹¤' ë“±ì˜ í™œìš©í˜• ë° ì˜¤íƒì§€ ë°©ì§€
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ìœ¼ë¯€ë¡œ', 'ì´ì–´ì§„', 'ì´ë£¨ì–´ì§„', 'ì´ë£¨ëŠ”', 'ì´ë™', 'ì´ìš©',
            'ì—†ëŠ”', 'ìˆëŠ”', 'ì—†ê³ ', 'ìˆê³ ', 'ì—†ì´', 'ìˆì–´', 'ì—†ì–´'
        ]

    def _init_batchim_dict(self):
        # ìŒë°›ì¹¨ ë“±ì„ í¬í•¨í•œ ë°›ì¹¨ ì—¬ë¶€ ì‚¬ì „ (LaTeX ì‹¬ë³¼ìš©)
        d = {
            '0': True, '1': True, '3': True, '6': True, '7': True, '8': True, '10': True,
            'l': True, 'm': True, 'n': True, 'r': True, 
            'L': True, 'M': True, 'N': True, 'R': True,
            'ì œê³±': True, 'ì—¬ì§‘í•©': True, 'ë°”': False
        }
        for c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…": d[c] = True
        # ìŒë°›ì¹¨ ë“±ì€ í•œê¸€ ìœ ë‹ˆì½”ë“œ ë¡œì§ì—ì„œ ì²˜ë¦¬ë˜ë‚˜, ëª…ì‹œì  ê¸°í˜¸ê°€ ìˆë‹¤ë©´ ì¶”ê°€
        for ch in '2459AaBbCcDdEeFfGgHhIiJjKkOoPpQqSsTtUuVvWwXxeYyZz':
            if ch not in d: d[ch] = False
        return d

    def _init_unit_batchim_dict(self):
        return {
            'm': False, 'cm': False, 'mm': False, 'km': False,
            'g': True, 'kg': True, 'mg': True,
            'l': False, 'L': False, 'mL': False,
            'A': False, 'V': False, 'W': False, 'Hz': False,
            'deg': False, 'degree': False
        }

    def _init_particle_pairs(self):
        return [
            ('ì´ë‹¤', 'ì´ë‹¤'), ('ì…ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤'),
            ('ì´ë¯€ë¡œ', 'ì´ë¯€ë¡œ'), ('ì´ë©°', 'ì´ë©°'), ('ì´ê³ ', 'ì´ê³ '), ('ì´ë‚˜', 'ì´ë‚˜'),
            ('ì´ë©´ì„œ', 'ì´ë©´ì„œ'), ('ì´ì§€ë§Œ', 'ì´ì§€ë§Œ'), ('ì´ì–´ì„œ', 'ì´ì–´ì„œ'),
            ('ì´ë•Œ', 'ì´ë•Œ'), ('ì´ì–´ì•¼ í•˜ë¯€ë¡œ', 'ì´ì–´ì•¼ í•˜ë¯€ë¡œ'),
            ('ê°€ì§€', 'ê°€ì§€'),
            ('ì´ë¼ì„œ', 'ë¼ì„œ'), ('ì´ë¼ê³ ', 'ë¼ê³ '), ('ì´ë¼', 'ë¼'), ('ì´ë©´', 'ë©´'), 
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ'), ('ì„', 'ìš¸')
        ]

    def get_balanced(self, text, start_idx):
        if start_idx == -1 or start_idx >= len(text): return None, start_idx
        count = 0
        for i in range(start_idx, len(text)):
            if text[i] == '{': count += 1
            elif text[i] == '}': count -= 1
            if count == 0: return text[start_idx+1:i], i + 1
        return None, start_idx

    def simplify_formula(self, latex_str):
        current = latex_str.replace(r'\left', '').replace(r'\right', '')
        prev_str = ""
        while prev_str != current:
            prev_str = current
            if '\\frac' in current:
                idx = current.find('\\frac')
                num, end_num = self.get_balanced(current, current.find('{', idx))
                _, end_den = self.get_balanced(current, current.find('{', end_num))
                if num is not None:
                    current = current[:idx] + num + current[end_den:]
                    continue
            if '\\sqrt' in current:
                idx = current.find('\\sqrt')
                if idx + 5 < len(current) and current[idx+5] == '[':
                    close_bracket = current.find(']', idx)
                    if close_bracket != -1:
                        current = current[:idx+5] + current[close_bracket+1:]
                        continue
            stripped = current.strip()
            if stripped.startswith('{') and stripped.endswith('}'):
                content, end = self.get_balanced(stripped, 0)
                if end == len(stripped):
                    current = content
                    continue
        return current

    def find_target(self, formula_str):
        simplified = self.simplify_formula(formula_str)
        clean = re.sub(r'\s+', '', simplified)
        masked_text = clean
        braces_content = []
        while True:
            start = masked_text.find('{')
            if start == -1: break
            content, end_idx = self.get_balanced(masked_text, start)
            if content is None: break
            placeholder = f"@BRACE{len(braces_content)}@"
            braces_content.append(content)
            masked_text = masked_text[:start] + placeholder + masked_text[end_idx:]

        split_pattern = (r'=|\\approx|\\ne|>|<|\\ge|\\le|\\times|\\div|'
                         r'(?<!\^)\+|(?<!\^)-|\\cdot|'
                         r'\\cap|\\cup|\\setminus|\\subset|\\subseteq|\\in|\\ni')
        parts = re.split(split_pattern, masked_text)
        final_term = parts[-1] if parts else masked_text

        while "@BRACE" in final_term:
            for i, content in enumerate(braces_content):
                placeholder = f"@BRACE{i}@"
                if placeholder in final_term:
                    final_term = final_term.replace(placeholder, "{" + content + "}")

        if r'\degree' in final_term or r'^\circ' in final_term: return "ë„"
        if "^" in final_term:
            if "C" in final_term: return "ì—¬ì§‘í•©"
            base_part = final_term.split('^')[0]
            mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', base_part)
            if mathrm_match:
                unit_content = mathrm_match.group(1)
                if unit_content in ['m', 'cm', 'mm', 'km']: return "ë¯¸í„°"
            return "ì œê³±"

        mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', final_term)
        if mathrm_match: return f"UNIT:{mathrm_match.group(1)}"

        if final_term.endswith(')'):
             m = re.search(r'([ê°€-í£a-zA-Z0-9])\)+$', final_term)
             if m: return m.group(1)

        text_only = re.sub(r'\\[a-zA-Z]+|[{}]|[()\[\]]|[\.,]', '', final_term)
        text_only = text_only.replace('\\', '').strip() 
        return text_only[-1] if text_only else ""

    def get_correct_p(self, target, original_p):
        # ë³´í˜¸ ë‹¨ì–´ ì²´í¬ (ì—¬ê¸°ì„œë„ í•œ ë²ˆ ë” í™•ì¸)
        for word in self.protected_words:
            if original_p.startswith(word): return original_p

        if not target.startswith("UNIT:") and len(target) == 1 and re.match(r'[a-zA-Z0-9]', target):
            is_noun_mask = False
            if original_p.startswith('ê°€ë©´'):
                after_mask = original_p[2:]
                if after_mask and after_mask[0] in ['ì„', 'ì´', 'ì€', 'ê³¼', 'ì˜', 'ë¡œ']: is_noun_mask = True
                if not is_noun_mask and original_p.startswith(('ì´ë©´', 'ë©´', 'ê°€ë©´')):
                    suffix = original_p[2:] if original_p.startswith('ê°€ë©´') else original_p[len('ì´ë©´' if original_p.startswith('ì´ë©´') else 'ë©´'):]
                    return 'ì´ë©´' + suffix

        has_batchim = False
        if target.startswith("UNIT:"):
            real_unit = target.split(":")[1]
            has_batchim = self.unit_batchim_dict.get(real_unit, False)
        elif target == "ë¯¸í„°": has_batchim = False
        else:
            if target in self.batchim_dict: has_batchim = self.batchim_dict[target]
            elif len(target) == 1 and 'ê°€' <= target <= 'í£': has_batchim = (ord(target) - 0xAC00) % 28 > 0
            elif len(target) > 1:
                last = target[-1]
                has_batchim = (ord(last) - 0xAC00) % 28 > 0 if 'ê°€' <= last <= 'í£' else self.batchim_dict.get(last, False)
            else: has_batchim = self.batchim_dict.get(target, False)

        is_rieul = target in ['1', '7', '8', 'L', 'R', 'l', 'r', 'ã„¹']
        
        for has_b, no_b in self.particle_pairs:
            if original_p.startswith(has_b) or original_p.startswith(no_b):
                if has_b == 'ìœ¼ë¡œ':
                    stem = 'ìœ¼ë¡œ' if (has_batchim and not is_rieul) else 'ë¡œ'
                else:
                    stem = has_b if has_batchim else no_b
                return stem + original_p[len(has_b if original_p.startswith(has_b) else no_b):]
        return original_p

    def clean_latex_for_human(self, latex):
        text = re.sub(r'\\(left|right|mathrm|text|bf|it)', '', latex)
        text = text.replace('{', '').replace('}', '').replace('\\', '')
        return text.strip()

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, raw_input):
        self.log = [] 
        try:
            if isinstance(raw_input, dict): input_data = raw_input
            else: input_data = json.loads(raw_input)
            target_text = input_data.get("result", raw_input) if isinstance(input_data, dict) else str(raw_input)
        except:
            target_text = str(raw_input)

        def replacer(match):
            pre, s1, formula, s2, particle = match.groups()
            p_match = re.search(r'[ê°€-í£]+', particle)
            
            match_start = match.start()
            match_end = match.end()

            if not p_match:
                if '.' in particle:
                    new_particle = particle.replace('.', '')
                    human_readable = self.clean_latex_for_human(formula)
                    context = self.get_context(target_text, match_start, match_end)
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": human_readable,
                        "ì›ë¬¸": particle,
                        "ìˆ˜ì •": new_particle,
                        "ì‚¬ìœ ": "ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ ì œê±°"
                    })
                    return f"{pre}{s1}${formula}${s2}{new_particle}"
                return match.group(0)

            p_start = p_match.start()
            original_p = p_match.group()
            remaining_particle = particle[p_start:]
            
            # [ì¤‘ìš”] ë³´í˜¸ ë‹¨ì–´ ì²´í¬: 'ì´ì€', 'ì—†ëŠ”' ë“±ì´ ìˆ˜ì‹ ë°”ë¡œ ë’¤ì— ì˜¬ ë•Œ ë³´í˜¸
            for word in self.protected_words:
                if remaining_particle.startswith(word): return match.group(0)
                
            target = self.find_target(formula)
            correct_p = self.get_correct_p(target, original_p)
            
            if original_p != correct_p:
                human_readable = self.clean_latex_for_human(formula)
                context = self.get_context(target_text, match_start, match_end)
                self.log.append({
                    "ë¬¸ë§¥": context,
                    "ëŒ€ìƒ": human_readable,
                    "ì›ë¬¸": original_p,
                    "ìˆ˜ì •": correct_p,
                    "ì‚¬ìœ ": "ë°›ì¹¨ í˜¸ì‘ ì˜¤ë¥˜"
                })

            return f"{pre}{s1}${formula}${s2}{particle[:p_start]}{correct_p}{particle[p_match.end():]}"

        pattern = r'([^$]*?)(\s*)\$([^\$]+)\$(\s*)([\s,]*[ê°€-í£\s\.\?\!]+)'
        fixed_text = re.sub(pattern, replacer, target_text, flags=re.DOTALL)
        return fixed_text, self.log

# ==========================================
# 2. í•œê¸€ ë§ì¶¤ë²•/ì˜¤íƒ€/ì¡°ì‚¬ êµì • í´ë˜ìŠ¤
# ==========================================
class SpellingCorrector:
    def __init__(self):
        self.log = []
        self.typo_dict = {
            "ìµœëŒ€ê°’": "ìµœëŒ“ê°’", "ìµœì†Œê°’": "ìµœì†Ÿê°’", "ê·¹ëŒ€ê°’": "ê·¹ëŒ“ê°’", "ê·¹ì†Œê°’": "ê·¹ì†Ÿê°’",
            "ì ˆëŒ€ê°’": "ì ˆëŒ“ê°’", "ê·¼ì‚¬ê°’": "ê·¼ì‚¿ê°’", "ëŒ€í‘œê°’": "ëŒ€í‘¯ê°’", "í•¨ìˆ˜ê°’": "í•¨ìˆ«ê°’",
            "ê¼­ì§€ì ": "ê¼­ì§“ì ", "ì´›ì ": "ì´ˆì ", "ê°¯ìˆ˜": "ê°œìˆ˜", "ë‚˜ëˆ„ê¸°": "ë‚˜ëˆ—ì…ˆ",
            "ì•Šë˜": "ì•ˆ ë˜", "ì•Šë¼": "ì•ˆ ë¼", "ì•Šëœë‹¤": "ì•ˆ ëœë‹¤", "ë¬¸ì•ˆ": "ë¬´ë‚œ",
            "ê¸ˆìƒˆ": "ê¸ˆì„¸", "ì—­í™œ": "ì—­í• ", "ì œì‘ë…„": "ì¬ì‘ë…„", "ì–´ë–»í•´": "ì–´ë–¡í•´",
            "ëª‡ì¼": "ë©°ì¹ ", "ë“¤ì–´ë‚˜ë‹¤": "ë“œëŸ¬ë‚˜ë‹¤", "ê°€ë¥´í‚¤ë‹¤": "ê°€ë¦¬í‚¤ë‹¤", "ë§ì¶”ë‹¤": "ë§íˆë‹¤"
        }
        self.korean_particle_pairs = [
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ')
        ]
        
        # [ì¶”ê°€] ì¡°ì‚¬ êµì • ì˜ˆì™¸ ëª©ë¡ (ë™ì‚¬/í˜•ìš©ì‚¬ í™œìš©í˜•)
        # 'ì—†ëŠ”' -> 'ì—†'(ë°›ì¹¨O) + 'ëŠ”' êµ¬ì¡°ì§€ë§Œ, 'ëŠ”'ì´ ì¡°ì‚¬ê°€ ì•„ë‹ˆë¯€ë¡œ 'ì€'ìœ¼ë¡œ ë°”ê¾¸ë©´ ì•ˆ ë¨.
        # 'ì´ì€' -> 'ì´'(ë°›ì¹¨X) + 'ì€' êµ¬ì¡°ì§€ë§Œ, 'ì€'ì´ ì¡°ì‚¬ê°€ ì•„ë‹ˆë¯€ë¡œ 'ëŠ”'ìœ¼ë¡œ ë°”ê¾¸ë©´ ì•ˆ ë¨.
        self.exceptions = {
            'ì—†ëŠ”', 'ìˆëŠ”', 'ê°–ëŠ”', 'ë§ëŠ”', 'ë§¡ëŠ”', 'ì›ƒëŠ”', 'ì”»ëŠ”', 'ê¹ëŠ”', 'ë³¶ëŠ”', 'ì•ŠëŠ”', # ë°›ì¹¨+ëŠ” (ë™ì‚¬)
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ì–´ì„œ', 'ê¹Šì€', 'ë†’ì€', 'ì‘ì€', 'ì¢ì€' # ë°›ì¹¨ìœ ë¬´+ì€ (í˜•ìš©ì‚¬/ë™ì‚¬ ê´€í˜•í˜•)
        }

    def has_batchim(self, char):
        # (char_code - 0xAC00) % 28 > 0 ì´ë©´ ë°›ì¹¨ì´ ìˆìŒ.
        # ìŒë°›ì¹¨(ã…†, ã…„ ë“±)ë„ ì´ ë¡œì§ì—ì„œ > 0 ì´ ë‚˜ì˜¤ë¯€ë¡œ ì •ìƒì ìœ¼ë¡œ 'ë°›ì¹¨ ìˆìŒ'ìœ¼ë¡œ ì²˜ë¦¬ë¨.
        if 'ê°€' <= char <= 'í£':
            return (ord(char) - 0xAC00) % 28 > 0
        return False

    def is_rieul_batchim(self, char):
        if 'ê°€' <= char <= 'í£':
            return (ord(char) - 0xAC00) % 28 == 8
        return False

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, text):
        self.log = []
        
        # LaTeX ìˆ˜ì‹ ë³´í˜¸
        parts = re.split(r'(\$[^\$]+\$)', text)
        
        final_parts = []
        
        for i, part in enumerate(parts):
            if i % 2 == 1: # ìˆ˜ì‹ ë¶€ë¶„
                final_parts.append(part)
                continue
            
            current_text = part
            
            # 1. ë‹¨ì–´ ì‚¬ì „ êµì •
            for wrong, correct in self.typo_dict.items():
                if wrong in current_text:
                    for m in re.finditer(re.escape(wrong), current_text):
                        context = self.get_context(current_text, m.start(), m.end())
                        self.log.append({
                            "ë¬¸ë§¥": context,
                            "ëŒ€ìƒ": wrong,
                            "ì›ë¬¸": wrong,
                            "ìˆ˜ì •": correct,
                            "ì‚¬ìœ ": "ë§ì¶¤ë²•/í‘œì¤€ì–´ ì˜¤ë¥˜"
                        })
                    current_text = current_text.replace(wrong, correct)
            
            # 2. í•œê¸€/ê¸°í˜¸ ì¡°ì‚¬ í˜¸ì‘ êµì •
            pattern = r'([ê°€-í£ã‰ -ã‰­])(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€|ìœ¼ë¡œ|ë¡œ)(?![ê°€-í£])'
            
            def josa_replacer(match):
                full_word = match.group(0) # ì˜ˆ: "ì—†ëŠ”", "ì´ì€"
                
                # [ì¤‘ìš”] ì˜ˆì™¸ ëª©ë¡ì— ìˆëŠ” ë‹¨ì–´(ë™ì‚¬/í˜•ìš©ì‚¬ í™œìš©í˜•)ëŠ” êµì •í•˜ì§€ ì•ŠìŒ
                if full_word in self.exceptions:
                    return full_word
                
                # ë¬¸ë§¥ìƒ ì˜ˆì™¸ ì²˜ë¦¬ (ê°„ë‹¨í•œ íœ´ë¦¬ìŠ¤í‹±)
                # ì˜ˆ: "ê°’ëŠ”" -> "ê°’ì€" (êµì • í•„ìš”), "ì—†ëŠ”" -> (ì˜ˆì™¸ ì²˜ë¦¬ë¨)
                
                noun_char = match.group(1)
                josa = match.group(2)
                
                if 'ê°€' <= noun_char <= 'í£':
                    has_bat = self.has_batchim(noun_char)
                    is_rieul = self.is_rieul_batchim(noun_char)
                else: 
                    has_bat = True
                    is_rieul = (noun_char == 'ã‰£')

                correct_josa = josa
                for bat_o, bat_x in self.korean_particle_pairs:
                    if josa == bat_o or josa == bat_x:
                        if bat_o == 'ìœ¼ë¡œ':
                            if not has_bat or is_rieul: correct_josa = 'ë¡œ'
                            else: correct_josa = 'ìœ¼ë¡œ'
                        else:
                            correct_josa = bat_o if has_bat else bat_x
                        break
                
                if josa != correct_josa:
                    context = self.get_context(current_text, match.start(), match.end())
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": full_word,
                        "ì›ë¬¸": josa,
                        "ìˆ˜ì •": correct_josa,
                        "ì‚¬ìœ ": "ì¡°ì‚¬ í˜¸ì‘ ì˜¤ë¥˜"
                    })
                    return f"{noun_char}{correct_josa}"
                return match.group(0)

            current_text = re.sub(pattern, josa_replacer, current_text)
            final_parts.append(current_text)
            
        return "".join(final_parts), self.log

# ==========================================
# 3. ë©”ì¸ UI (Streamlit)
# ==========================================
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°", layout="wide")

st.title("âœ¨ ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°")
st.markdown("""
**1. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘:** LaTeX ìˆ˜ì‹ ë’¤ì˜ ì¡°ì‚¬ë¥¼ êµì •í•©ë‹ˆë‹¤. ('ì´ì€', 'ì—†ëŠ”' ë“± ë™ì‚¬ í™œìš©í˜• ì˜¤íƒì§€ ë°©ì§€ ì ìš©)  
**2. í•œê¸€ ë§ì¶¤ë²•:** ìŒë°›ì¹¨ ë‹¨ì–´('ì—†ëŠ”')ë‚˜ 'ì´ì€' ì²˜ëŸ¼ ì¡°ì‚¬ê°€ ì•„ë‹Œ ì–´ë¯¸ë¥¼ ì¡°ì‚¬ë¡œ ì°©ê°í•˜ëŠ” ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
""")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ì…ë ¥ (Input)")
    input_val = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", height=600, 
                             placeholder="ì˜ˆ: $x$ê°€ ì—†ëŠ” ê²½ìš°, ë‘ ì  $A$, $B$ë¥¼ ì´ì€ ì„ ë¶„ì€...")

with col2:
    st.subheader("ê²€ìˆ˜ ë¦¬í¬íŠ¸ (Report)")
    
    if input_val:
        # 1. ì¡°ì‚¬ êµì • ì‹¤í–‰
        josa_corrector = JosaCorrector()
        temp_text, josa_logs = josa_corrector.run(input_val)
        
        # 2. ë§ì¶¤ë²• êµì • ì‹¤í–‰
        spell_corrector = SpellingCorrector()
        final_text, spell_logs = spell_corrector.run(temp_text)
        
        # --- ë¦¬í¬íŠ¸ ì¶œë ¥ ---
        tab1, tab2 = st.tabs(["ğŸ” ìˆ˜ì‹ ì¡°ì‚¬ ê²€ìˆ˜", "ğŸ“ í•œê¸€/ê¸°í˜¸ ê²€ìˆ˜"])
        
        with tab1:
            if josa_logs:
                st.error(f"ìˆ˜ì‹ ì¡°ì‚¬ ì˜¤ë¥˜: {len(josa_logs)}ê±´")
                df_josa = pd.DataFrame(josa_logs)
                cols = ['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']
                st.dataframe(df_josa[cols], use_container_width=True, hide_index=True)
            else:
                st.success("ìˆ˜ì‹ ì¡°ì‚¬ê°€ ì™„ë²½í•©ë‹ˆë‹¤.")
                
        with tab2:
            if spell_logs:
                st.warning(f"í•œê¸€/ê¸°í˜¸ ì˜¤ë¥˜: {len(spell_logs)}ê±´")
                df_spell = pd.DataFrame(spell_logs)
                cols = ['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']
                st.dataframe(df_spell[cols], use_container_width=True, hide_index=True)
            else:
                st.success("ë°œê²¬ëœ ì˜¤íƒ€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("ìµœì¢… ê²°ê³¼ë¬¼ (Result)")
        st.text_area("êµì •ëœ í…ìŠ¤íŠ¸", value=final_text, height=300)
        
        st.download_button(
            label="ğŸ’¾ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=final_text,
            file_name="corrected_result.txt",
            mime="text/plain"
        )
    else:
        st.info("ì™¼ìª½ì— ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")