import streamlit as st
import re
import json
import pandas as pd

# ==========================================
# 1. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘ êµì • í´ë˜ìŠ¤ (LaTeX ëŒ€ìƒ)
# ==========================================
class JosaCorrector:
    def __init__(self):
        self.log = []
        self.batchim_dict = self._init_batchim_dict()
        self.unit_batchim_dict = self._init_unit_batchim_dict()
        self.particle_pairs = self._init_particle_pairs()
        
        # [ìˆ˜ì‹ ë³´í˜¸] ì¡°ì‚¬ê°€ ì•„ë‹Œ ë‹¨ì–´(ë™ì‚¬/í˜•ìš©ì‚¬ í™œìš©í˜•) ë³´í˜¸ ëª©ë¡
        self.protected_words = [
            'ì´ë‹¤', 'ì…ë‹ˆë‹¤', 'ì´ë¯€ë¡œ', 'ì´ë©°', 'ì´ê³ ', 'ì´ë‚˜', 'ì´ë©´ì„œ', 'ì´ì§€ë§Œ', 'ì´ì–´ì„œ',
            'ì´ë•Œ', 'ì´ì–´ì•¼', 'ê°€ì§€',
            'ì´ë©´', 
            'ì´ìƒ', 'ì´í•˜', 'ì´ë‚´', 'ì´ì™¸', 'ë¯¸ë§Œ', 'ì´ˆê³¼',
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ìœ¼ë¯€ë¡œ', 'ì´ì–´ì§„', 'ì´ë£¨ì–´ì§„', 'ì´ë£¨ëŠ”', 'ì´ë™', 'ì´ìš©',
            'ì—†ëŠ”', 'ìˆëŠ”', 'ì—†ê³ ', 'ìˆê³ ', 'ì—†ì´', 'ìˆì–´', 'ì—†ì–´'
        ]

    def _init_batchim_dict(self):
        d = {
            '0': True, '1': True, '3': True, '6': True, '7': True, '8': True, '10': True,
            'l': True, 'm': True, 'n': True, 'r': True, 
            'L': True, 'M': True, 'N': True, 'R': True,  # Mì€ 'ì— ' -> ë°›ì¹¨ ìˆìŒ
            'ì œê³±': True, 'ì—¬ì§‘í•©': True, 'ë°”': False
        }
        for c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…": d[c] = True
        for ch in '2459AaBbCcDdEeFfGgHhIiJjKkOoPpQqSsTtUuVvWwXxeYyZz':
            if ch not in d: d[ch] = False
        return d

    def _init_unit_batchim_dict(self):
        return {
            'm': False, 'cm': False, 'mm': False, 'km': False,
            'g': True, 'kg': True, 'mg': True,
            'l': False, 'L': False, 'mL': False,
            'A': False, 'V': False, 'W': False, 'Hz': False,
            'deg': False, 'degree': False,
            'N': True  # ë‰´í„´(N)ì€ ë°›ì¹¨ ìˆìŒ
        }

    def _init_particle_pairs(self):
        return [
            ('ì´ë‹¤', 'ì´ë‹¤'), ('ì…ë‹ˆë‹¤', 'ì…ë‹ˆë‹¤'),
            ('ì´ë¯€ë¡œ', 'ì´ë¯€ë¡œ'), ('ì´ë©°', 'ì´ë©°'), ('ì´ê³ ', 'ì´ê³ '), ('ì´ë‚˜', 'ì´ë‚˜'),
            ('ì´ë©´ì„œ', 'ì´ë©´ì„œ'), ('ì´ì§€ë§Œ', 'ì´ì§€ë§Œ'), ('ì´ì–´ì„œ', 'ì´ì–´ì„œ'),
            ('ì´ë•Œ', 'ì´ë•Œ'), ('ì´ì–´ì•¼ í•˜ë¯€ë¡œ', 'ì´ì–´ì•¼ í•˜ë¯€ë¡œ'),
            ('ê°€ì§€', 'ê°€ì§€'),
            ('ì´ë¼ì„œ', 'ë¼ì„œ'), ('ì´ë¼ê³ ', 'ë¼ê³ '), ('ì´ë¼', 'ë¼'), ('ì´ë©´', 'ë©´'), 
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ'), ('ì„', 'ìš¸')
        ]

    def get_balanced(self, text, start_idx):
        if start_idx == -1 or start_idx >= len(text): return None, start_idx
        count = 0
        for i in range(start_idx, len(text)):
            if text[i] == '{': count += 1
            elif text[i] == '}': count -= 1
            if count == 0: return text[start_idx+1:i], i + 1
        return None, start_idx

    def simplify_formula(self, latex_str):
        # 1. \left, \right ì œê±°
        current = latex_str.replace(r'\left', '').replace(r'\right', '')
        
        prev_str = ""
        while prev_str != current:
            prev_str = current
            # 2. \frac{A}{B} -> A (í•œêµ­ì–´ ì½ê¸° ìˆœì„œ: Bë¶„ì˜ A -> ëì†Œë¦¬ëŠ” A)
            if '\\frac' in current:
                idx = current.find('\\frac')
                # ë¶„ì ì°¾ê¸°
                num_start = current.find('{', idx)
                num, end_num = self.get_balanced(current, num_start)
                # ë¶„ëª¨ ì°¾ê¸°
                den_start = current.find('{', end_num)
                _, end_den = self.get_balanced(current, den_start)
                
                if num is not None:
                    # ì „ì²´ \frac{...}{...}ë¥¼ ë¶„ì(num)ë¡œ ëŒ€ì²´
                    current = current[:idx] + num + current[end_den:]
                    continue
            
            # 3. \sqrt, \sqrt[...] ì œê±°
            if '\\sqrt' in current:
                idx = current.find('\\sqrt')
                if idx + 5 < len(current) and current[idx+5] == '[':
                    close_bracket = current.find(']', idx)
                    if close_bracket != -1:
                        current = current[:idx+5] + current[close_bracket+1:]
                        continue
            
            # 4. ë°”ê¹¥ìª½ ì¤‘ê´„í˜¸ ì œê±° ({...} -> ...)
            stripped = current.strip()
            if stripped.startswith('{') and stripped.endswith('}'):
                content, end = self.get_balanced(stripped, 0)
                if end == len(stripped):
                    current = content
                    continue
        return current

    def find_target(self, formula_str):
        simplified = self.simplify_formula(formula_str)
        clean = re.sub(r'\s+', '', simplified)
        
        # ì¤‘ê´„í˜¸ ë‚´ìš© ë³´í˜¸
        masked_text = clean
        braces_content = []
        while True:
            start = masked_text.find('{')
            if start == -1: break
            content, end_idx = self.get_balanced(masked_text, start)
            if content is None: break
            placeholder = f"@BRACE{len(braces_content)}@"
            braces_content.append(content)
            masked_text = masked_text[:start] + placeholder + masked_text[end_idx:]

        # ì—°ì‚°ìë¡œ ë¶„ë¦¬í•˜ì—¬ ë§ˆì§€ë§‰ í•­ ì¶”ì¶œ
        split_pattern = (r'=|\\approx|\\ne|>|<|\\ge|\\le|\\times|\\div|'
                         r'(?<!\^)\+|(?<!\^)-|\\cdot|'
                         r'\\cap|\\cup|\\setminus|\\subset|\\subseteq|\\in|\\ni')
        parts = re.split(split_pattern, masked_text)
        final_term = parts[-1] if parts else masked_text

        # ë³´í˜¸ëœ ë‚´ìš© ë³µì›
        while "@BRACE" in final_term:
            for i, content in enumerate(braces_content):
                placeholder = f"@BRACE{i}@"
                if placeholder in final_term:
                    final_term = final_term.replace(placeholder, "{" + content + "}")

        # ëë¶€ë¶„ ì •ë¦¬ (ì—­ìŠ¬ë˜ì‹œ ë“±)
        final_term = final_term.rstrip('\\').strip()

        # 1. ë„(degree) ì²˜ë¦¬
        if r'\degree' in final_term or r'^\circ' in final_term: return "ë„"
        
        # 2. ì§€ìˆ˜(^) ì²˜ë¦¬
        if "^" in final_term:
            if "C" in final_term: return "ì—¬ì§‘í•©"
            base_part = final_term.split('^')[0]
            # ë‹¨ìœ„ í™•ì¸
            mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', base_part)
            if mathrm_match:
                unit_content = mathrm_match.group(1)
                if unit_content in ['m', 'cm', 'mm', 'km']: return "ë¯¸í„°"
            return "ì œê³±"

        # 3. ê´„í˜¸ë¡œ ëë‚˜ëŠ” ê²½ìš° (í•¨ìˆ˜ ë“±) -> ë‚´ë¶€ì˜ ë§ˆì§€ë§‰ ê¸€ì í™•ì¸
        if final_term.endswith(')'):
             m = re.search(r'([ê°€-í£a-zA-Z0-9])\)+$', final_term)
             if m: return m.group(1)

        # 4. ë‹¨ìœ„(mathrm) ì²˜ë¦¬
        mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', final_term)
        if mathrm_match: return f"UNIT:{mathrm_match.group(1)}"

        # 5. í…ìŠ¤íŠ¸ë§Œ ì¶”ì¶œ (ëª…ë ¹ì–´ ì œê±°)
        text_only = re.sub(r'\\[a-zA-Z]+|[{}]|[()\[\]]|[\.,]', '', final_term)
        text_only = text_only.replace('\\', '').strip() 
        
        return text_only[-1] if text_only else ""

    def get_correct_p(self, target, original_p):
        for word in self.protected_words:
            if original_p.startswith(word): return original_p

        if not target.startswith("UNIT:") and len(target) == 1 and re.match(r'[a-zA-Z0-9]', target):
            is_noun_mask = False
            if original_p.startswith('ê°€ë©´'):
                after_mask = original_p[2:]
                if after_mask and after_mask[0] in ['ì„', 'ì´', 'ì€', 'ê³¼', 'ì˜', 'ë¡œ']: is_noun_mask = True
                if not is_noun_mask and original_p.startswith(('ì´ë©´', 'ë©´', 'ê°€ë©´')):
                    suffix = original_p[2:] if original_p.startswith('ê°€ë©´') else original_p[len('ì´ë©´' if original_p.startswith('ì´ë©´') else 'ë©´'):]
                    return 'ì´ë©´' + suffix

        has_batchim = False
        if target.startswith("UNIT:"):
            real_unit = target.split(":")[1]
            has_batchim = self.unit_batchim_dict.get(real_unit, False)
        elif target == "ë¯¸í„°": has_batchim = False
        else:
            if target in self.batchim_dict: has_batchim = self.batchim_dict[target]
            elif len(target) == 1 and 'ê°€' <= target <= 'í£': has_batchim = (ord(target) - 0xAC00) % 28 > 0
            elif len(target) > 1:
                last = target[-1]
                has_batchim = (ord(last) - 0xAC00) % 28 > 0 if 'ê°€' <= last <= 'í£' else self.batchim_dict.get(last, False)
            else: has_batchim = self.batchim_dict.get(target, False)

        is_rieul = target in ['1', '7', '8', 'L', 'R', 'l', 'r', 'ã„¹']
        
        for has_b, no_b in self.particle_pairs:
            if original_p.startswith(has_b) or original_p.startswith(no_b):
                if has_b == 'ìœ¼ë¡œ':
                    stem = 'ìœ¼ë¡œ' if (has_batchim and not is_rieul) else 'ë¡œ'
                else:
                    stem = has_b if has_batchim else no_b
                return stem + original_p[len(has_b if original_p.startswith(has_b) else no_b):]
        return original_p

    def clean_latex_for_human(self, latex):
        text = re.sub(r'\\(left|right|mathrm|text|bf|it)', '', latex)
        text = text.replace('{', '').replace('}', '').replace('\\', '')
        return text.strip()

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, raw_input):
        self.log = [] 
        try:
            if isinstance(raw_input, dict): input_data = raw_input
            else: input_data = json.loads(raw_input)
            target_text = input_data.get("result", raw_input) if isinstance(input_data, dict) else str(raw_input)
        except:
            target_text = str(raw_input)

        def replacer(match):
            pre, s1, delim, formula, gap, particle = match.groups()
            formula_clean = formula.replace('\\\\', '\\')
            
            p_match = re.search(r'[ê°€-í£]+', particle)
            match_start = match.start()
            match_end = match.end()

            if not p_match:
                if '.' in particle:
                    new_particle = particle.replace('.', '')
                    human_readable = self.clean_latex_for_human(formula_clean)
                    context = self.get_context(target_text, match_start, match_end)
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": human_readable,
                        "ì›ë¬¸": particle,
                        "ìˆ˜ì •": new_particle,
                        "ì‚¬ìœ ": "ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ ì œê±°"
                    })
                    return f"{pre}{s1}{delim}{formula}{delim}{gap}{new_particle}"
                return match.group(0)

            p_start = p_match.start()
            original_p = p_match.group()
            remaining_particle = particle[p_start:]
            
            for word in self.protected_words:
                if remaining_particle.startswith(word): return match.group(0)
                
            target = self.find_target(formula_clean)
            correct_p = self.get_correct_p(target, original_p)
            
            if original_p != correct_p:
                human_readable = self.clean_latex_for_human(formula_clean)
                context = self.get_context(target_text, match_start, match_end)
                self.log.append({
                    "ë¬¸ë§¥": context,
                    "ëŒ€ìƒ": human_readable,
                    "ì›ë¬¸": original_p,
                    "ìˆ˜ì •": correct_p,
                    "ì‚¬ìœ ": "ë°›ì¹¨ í˜¸ì‘ ì˜¤ë¥˜"
                })
                return f"{pre}{s1}{delim}{formula}{delim}{gap}{particle[:p_start]}{correct_p}{particle[p_match.end():]}"

            return match.group(0)

        pattern = r'([^$]*?)(\s*)(\$+)([^\$]+)\3((?:[\s,]|(?:\\[a-zA-Z]+)|(?:\\.)|(?:\$(?:(?:\\[a-zA-Z]+)|(?:\\.)|[\s])*\$))*)([ê°€-í£\s\.\?\!]+)'
        fixed_text = re.sub(pattern, replacer, target_text, flags=re.DOTALL)
        return fixed_text, self.log

# ==========================================
# 2. í•œê¸€ ë§ì¶¤ë²•/ì˜¤íƒ€/ì¡°ì‚¬ êµì • í´ë˜ìŠ¤
# ==========================================
class SpellingCorrector:
    def __init__(self):
        self.log = []
        self.typo_dict = {
            "ìë¦¬ìˆ˜": "ìë¦¿ìˆ˜", "ìµœëŒ€ê°’": "ìµœëŒ“ê°’", "ìµœì†Œê°’": "ìµœì†Ÿê°’", "ê·¹ëŒ€ê°’": "ê·¹ëŒ“ê°’", "ê·¹ì†Œê°’": "ê·¹ì†Ÿê°’",
            "ì ˆëŒ€ê°’": "ì ˆëŒ“ê°’", "ê·¼ì‚¬ê°’": "ê·¼ì‚¿ê°’", "ëŒ€í‘œê°’": "ëŒ€í‘¯ê°’", "í•¨ìˆ˜ê°’": "í•¨ìˆ«ê°’",
            "ê¼­ì§€ì ": "ê¼­ì§“ì ", "ì´›ì ": "ì´ˆì ", "ê°¯ìˆ˜": "ê°œìˆ˜", "ë‚˜ëˆ„ê¸°": "ë‚˜ëˆ—ì…ˆ",
            "ì•Šë˜": "ì•ˆ ë˜", "ì•Šë¼": "ì•ˆ ë¼", "ì•Šëœë‹¤": "ì•ˆ ëœë‹¤", "ë¬¸ì•ˆ": "ë¬´ë‚œ",
            "ê¸ˆìƒˆ": "ê¸ˆì„¸", "ì—­í™œ": "ì—­í• ", "ì œì‘ë…„": "ì¬ì‘ë…„", "ì–´ë–»í•´": "ì–´ë–¡í•´",
            "ëª‡ì¼": "ë©°ì¹ ", "ë“¤ì–´ë‚˜ë‹¤": "ë“œëŸ¬ë‚˜ë‹¤", "ê°€ë¥´í‚¤ë‹¤": "ê°€ë¦¬í‚¤ë‹¤", "ë§ì¶”ë‹¤": "ë§íˆë‹¤"
        }
        self.korean_particle_pairs = [
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ')
        ]
        
        self.exceptions = {
            'ì¦ê°€', 'ì¶”ê°€', 'ê²°ê³¼', 'íš¨ê³¼', 'ì´ˆê³¼', 'êµê³¼', 'ë¶€ê³¼', 'ì‚¬ê³¼', 'íˆ¬ê³¼',
            'í‰ê°€', 'ì›ê°€', 'ì •ê°€', 'ë‹¨ê°€', 'ì‹œê°€',
            'ì‚¬ì´', 'ì°¨ì´', 'ë‚˜ì´', 'ì•„ì´', 'ì˜¤ì´', 'ë†€ì´',
            'ê²½ë¡œ', 'ì§„ë¡œ', 'ì„ ë¡œ', 'í•­ë¡œ',
            'ì—†ëŠ”', 'ìˆëŠ”', 'ê°–ëŠ”', 'ë§ëŠ”', 'ë§¡ëŠ”', 'ì›ƒëŠ”', 'ì”»ëŠ”', 'ê¹ëŠ”', 'ë³¶ëŠ”', 'ì•ŠëŠ”',
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ì–´ì„œ', 'ê¹Šì€', 'ë†’ì€', 'ì‘ì€', 'ì¢ì€',
            'ì¸ê°€', 'ëŠ”ê°€', 'ì€ê°€', 'ë˜ê°€', 'ë‚˜', 'ê°€' 
        }

    def has_batchim(self, char):
        if 'ê°€' <= char <= 'í£':
            return (ord(char) - 0xAC00) % 28 > 0
        return False

    def is_rieul_batchim(self, char):
        if 'ê°€' <= char <= 'í£':
            return (ord(char) - 0xAC00) % 28 == 8
        return False

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, text):
        self.log = []
        parts = re.split(r'(\$[^\$]+\$)', text)
        final_parts = []
        
        for i, part in enumerate(parts):
            if i % 2 == 1:
                final_parts.append(part)
                continue
            
            current_text = part
            for wrong, correct in self.typo_dict.items():
                if wrong in current_text:
                    for m in re.finditer(re.escape(wrong), current_text):
                        context = self.get_context(current_text, m.start(), m.end())
                        self.log.append({
                            "ë¬¸ë§¥": context,
                            "ëŒ€ìƒ": wrong,
                            "ì›ë¬¸": wrong,
                            "ìˆ˜ì •": correct,
                            "ì‚¬ìœ ": "ë§ì¶¤ë²•/í‘œì¤€ì–´ ì˜¤ë¥˜"
                        })
                    current_text = current_text.replace(wrong, correct)
            
            # [ìˆ˜ì •] ì§€ì‹œ ê´€í˜•ì‚¬ 'ì´', 'ê·¸', 'ì €' ì˜ˆì™¸ ì²˜ë¦¬ ì¶”ê°€
            # 'ì´ ì ì€' -> 'ì´'ëŠ” ì§€ì‹œì–´ì´ë¯€ë¡œ ì¡°ì‚¬ êµì • ëŒ€ìƒì—ì„œ ì œì™¸
            # íŒ¨í„´: (í•œê¸€)(ì¡°ì‚¬)(ë’¤ì— í•œê¸€ì´ ì˜¤ì§€ ì•ŠìŒ)
            pattern = r'([ê°€-í£ã‰ -ã‰­])(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€|ìœ¼ë¡œ|ë¡œ)(?![ê°€-í£])'
            
            def josa_replacer(match):
                full_word = match.group(0)
                noun_char = match.group(1)
                josa = match.group(2)
                
                # 1. ì˜ˆì™¸ ë‹¨ì–´ ëª©ë¡ ì²´í¬
                if full_word in self.exceptions:
                    return full_word

                # 2. ì§€ì‹œ ê´€í˜•ì‚¬ ì˜ˆì™¸ ì²˜ë¦¬ ('ì´ ì ', 'ê·¸ ì‚¬ëŒ', 'ì € ê³³')
                # 'ì´', 'ê·¸', 'ì €' ë‹¨ë…ìœ¼ë¡œ ì“°ì´ê³  ë’¤ì— ì¡°ì‚¬ê°€ ë¶™ì€ ê²ƒì²˜ëŸ¼ ë³´ì¼ ë•Œ (ì‹¤ì œë¡œëŠ” ì§€ì‹œì–´+ì¡°ì‚¬ê°€ ì•„ë‹˜)
                # í•˜ì§€ë§Œ ì—¬ê¸°ì„œëŠ” 'ì´' ìì²´ê°€ ëª…ì‚¬(noun_char)ë¡œ ì¡íˆê³  'ê°€'(josa)ê°€ ë¶™ëŠ” ê²½ìš°ë¥¼ ì²´í¬í•¨.
                # 'ì´ ì ì€'ì˜ ê²½ìš°: noun_char='ì´', josa='ì '(ì¡°ì‚¬ ì•„ë‹˜) -> ì´ íŒ¨í„´ì— ì•ˆ ê±¸ë¦¼.
                # ë¬¸ì œëŠ” 'ì´' ë‹¨ë…ìœ¼ë¡œ ì“°ì¼ ë•Œì„.
                # ì‚¬ìš©ìê°€ ì§€ì í•œ 'ì´ ì ì€'ì—ì„œ 'ì´'ëŠ” ì§€ì‹œì–´.
                # í˜„ì¬ ì •ê·œì‹ì€ 'ì´'ë¥¼ ëª…ì‚¬ë¡œ, ë’¤ì— ì˜¤ëŠ” ê¸€ìë¥¼ ì¡°ì‚¬ë¡œ ë³´ëŠ”ë°, 'ì 'ì€ ì¡°ì‚¬ê°€ ì•„ë‹˜.
                # ë”°ë¼ì„œ 'ì´ ì ì€'ì€ ì›ë˜ ì •ê·œì‹ì— ì•ˆ ê±¸ë ¤ì•¼ ì •ìƒì„.
                # í•˜ì§€ë§Œ ë§Œì•½ 'ì´' ë’¤ì— ì¡°ì‚¬ê°€ ë¶™ëŠ” ê²½ìš° (ì˜ˆ: 'ì´ê°€')ë¥¼ ì˜¤ì¸í•  ìˆ˜ ìˆìŒ.
                
                # ì‚¬ìš©ìì˜ ì§€ì : "'ì´ ì ì€' í• ë•Œ 'ì´'ëŠ” ì§€ì‹œì–´ì§€ ì¡°ì‚¬ê°€ ì•„ë‹ˆì•¼"
                # -> ì•„ë§ˆë„ ì½”ë“œ ì–´ë”˜ê°€ì—ì„œ 'ì´'ë¥¼ ì¡°ì‚¬ë¡œ ì¸ì‹í•´ì„œ ì• ë‹¨ì–´ì™€ ë¶™ì´ë ¤ í–ˆê±°ë‚˜,
                # 'ì´' ìì²´ë¥¼ ëª…ì‚¬ë¡œ ë³´ê³  ë’¤ì— ì˜¤ëŠ” ê²ƒì„ ì¡°ì‚¬ë¡œ ì°©ê°í–ˆì„ ìˆ˜ ìˆìŒ.
                # ì—¬ê¸°ì„œëŠ” 'ì´'ê°€ ë…ë¦½ëœ ë‹¨ì–´(ì§€ì‹œì–´)ì¼ ë•Œ êµì •í•˜ì§€ ì•Šë„ë¡ í•¨.
                
                # ë§Œì•½ matchê°€ ë¬¸ì¥ì˜ ì‹œì‘ì´ê±°ë‚˜ ì•ì´ ê³µë°±ì´ë©´ ì§€ì‹œì–´ì¼ í™•ë¥  ë†’ìŒ
                # í•˜ì§€ë§Œ ì •ê·œì‹ì€ ë¬¸ë§¥ì„ ì™„ë²½íˆ ëª¨ë¥´ë¯€ë¡œ, 'ì´', 'ê·¸', 'ì €' ë‹¨ë… ê¸€ìëŠ” ê±´ë„ˆëœ€
                if noun_char in ['ì´', 'ê·¸', 'ì €'] and josa in ['ê°€', 'ëŠ”', 'ë¥¼', 'ì™€', 'ë¡œ']:
                    # 'ì´ê°€', 'ê·¸ëŠ”', 'ì €ë¥¼' -> ëŒ€ëª…ì‚¬+ì¡°ì‚¬ì¼ ìˆ˜ë„ ìˆê³  ì§€ì‹œì–´+ëª…ì‚¬ì¼ ìˆ˜ë„ ì—†ìŒ(ë„ì–´ì“°ê¸° ì—†ìœ¼ë¯€ë¡œ)
                    # ë„ì–´ì“°ê¸°ê°€ ë˜ì–´ ìˆë‹¤ë©´ ì •ê·œì‹ (?![ê°€-í£]) ë•Œë¬¸ì— ì•ˆ ì¡í˜.
                    # 'ì´ ì ì€' -> 'ì´'ì™€ 'ì ' ì‚¬ì´ì— ê³µë°±ì´ ìˆë‹¤ë©´ ì´ ì •ê·œì‹ì— ì•ˆ ì¡í˜.
                    # ë§Œì•½ 'ì´ì ì€'ìœ¼ë¡œ ë¶™ì–´ìˆë‹¤ë©´ 'ì´'ë¥¼ ëª…ì‚¬, 'ì 'ì„ ì¡°ì‚¬ë¡œ ë³´ì§€ ì•ŠìŒ ('ì 'ì€ ì¡°ì‚¬ ëª©ë¡ì— ì—†ìŒ).
                    pass

                # 3. ë°›ì¹¨ í™•ì¸ ë° êµì •
                if 'ê°€' <= noun_char <= 'í£':
                    has_bat = self.has_batchim(noun_char)
                    is_rieul = self.is_rieul_batchim(noun_char)
                else: 
                    has_bat = True
                    is_rieul = (noun_char == 'ã‰£')

                correct_josa = josa
                for bat_o, bat_x in self.korean_particle_pairs:
                    if josa == bat_o or josa == bat_x:
                        if bat_o == 'ìœ¼ë¡œ':
                            if not has_bat or is_rieul: correct_josa = 'ë¡œ'
                            else: correct_josa = 'ìœ¼ë¡œ'
                        else:
                            correct_josa = bat_o if has_bat else bat_x
                        break
                
                if josa != correct_josa:
                    # ì§€ì‹œì–´ 'ì´', 'ê·¸', 'ì €' ë’¤ì— ì¡°ì‚¬ê°€ ì˜ëª» ë¶™ì€ ê²½ìš° (ì˜ˆ: 'ì´ì€' -> 'ì´ëŠ”')ëŠ” êµì •í•´ì•¼ í•¨.
                    # í•˜ì§€ë§Œ 'ì´ ì ì€' ì²˜ëŸ¼ ë„ì–´ì“°ê¸°ê°€ ìˆëŠ” ê²½ìš°, ì´ ì •ê·œì‹ì€ ì‘ë™í•˜ì§€ ì•ŠìŒ (ê³µë°± í¬í•¨ ì•ˆ í•¨).
                    # ë”°ë¼ì„œ ì‚¬ìš©ìì˜ ì§€ì ì€ 'ì´'ë¥¼ ì¡°ì‚¬ë¡œ ì°©ê°í•´ì„œ ì•ë§ì— ë¶™ì´ëŠ” ê²½ìš°ì¼ ìˆ˜ ìˆìŒ.
                    # (ì˜ˆ: "ê°’ ì´" -> "ê°’ì´") -> ì´ ì½”ë“œëŠ” ë„ì–´ì“°ê¸° êµì •ì€ ì•ˆ í•¨.
                    
                    # í˜¹ì‹œ 'ì´'ë¥¼ ì¡°ì‚¬ë¡œ ë³´ê³  ì• ë‹¨ì–´ì˜ ë°›ì¹¨ì— ë”°ë¼ 'ê°€'ë¡œ ë°”ê¾¸ëŠ” ê²½ìš°?
                    # ì˜ˆ: "ì‚¬ëŒ ì´" (X) -> ì´ ì½”ë“œëŠ” ë„ì–´ì“°ê¸° ë¬´ì‹œ ì•ˆ í•¨.
                    
                    # ì‚¬ìš©ìì˜ ì˜ë„: "ì´ ì ì€"ì—ì„œ 'ì´'ê°€ ì¡°ì‚¬ 'ì´/ê°€'ì˜ 'ì´'ë¡œ ì¸ì‹ë˜ì–´ 'ê°€'ë¡œ ë°”ë€ŒëŠ” ê²ƒì„ ë°©ì§€.
                    # ì¦‰, ì• ë‹¨ì–´ê°€ ì—†ê³  ë¬¸ë‘ì— 'ì´'ê°€ ë‚˜ì˜¬ ë•Œ.
                    # í˜„ì¬ ì •ê·œì‹ì€ `([ê°€-í£])(ì¡°ì‚¬)` í˜•íƒœì´ë¯€ë¡œ ì• ê¸€ìê°€ ë°˜ë“œì‹œ ìˆì–´ì•¼ í•¨.
                    # ë”°ë¼ì„œ "ì´ ì ì€"ì˜ 'ì´'ê°€ ì¡°ì‚¬ë¡œ ì¡íˆë ¤ë©´ ì• ê¸€ìê°€ ìˆì–´ì•¼ í•¨.
                    # ë§Œì•½ ë¬¸ì¥ ë§¨ ì•ì´ë¼ë©´ ì¡íˆì§€ ì•ŠìŒ.
                    
                    # ê²°ë¡ : ì‚¬ìš©ìê°€ ê²ªì€ ì˜¤ë¥˜ëŠ” ì•„ë§ˆë„ ì´ì „ í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê³¼ì •ì—ì„œ
                    # "A ì´ ì ì€" ì²˜ëŸ¼ ì•ì— ë­”ê°€ê°€ ìˆê³  'ì´'ë¥¼ ì¡°ì‚¬ë¡œ ì¸ì‹í–ˆì„ ê°€ëŠ¥ì„±.
                    # ì—¬ê¸°ì„œëŠ” ì•ˆì „í•˜ê²Œ 'ì´', 'ê·¸', 'ì €'ê°€ ëª…ì‚¬ ìœ„ì¹˜(noun_char)ì— ì˜¤ë©´ êµì •í•˜ì§€ ì•Šë„ë¡ í•¨.
                    if noun_char in ['ì´', 'ê·¸', 'ì €']:
                        return full_word

                    context = self.get_context(current_text, match.start(), match.end())
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": full_word,
                        "ì›ë¬¸": josa,
                        "ìˆ˜ì •": correct_josa,
                        "ì‚¬ìœ ": "ì¡°ì‚¬ í˜¸ì‘ ì˜¤ë¥˜"
                    })
                    return f"{noun_char}{correct_josa}"
                return match.group(0)

            current_text = re.sub(pattern, josa_replacer, current_text)
            final_parts.append(current_text)
            
        return "".join(final_parts), self.log

# ==========================================
# 3. ë©”ì¸ UI (Streamlit)
# ==========================================
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°", layout="wide")

st.title("âœ¨ ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°")
st.markdown("""
**1. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘:** LaTeX ìˆ˜ì‹ ë’¤ì˜ ì¡°ì‚¬ë¥¼ êµì •í•©ë‹ˆë‹¤. (ì‰¼í‘œ ë’¤ 'ì´ë©´' ìœ ì§€)  
**2. í•œê¸€ ë§ì¶¤ë²•:** 'ëª‡ ê°œì¸ê°€?' ì²˜ëŸ¼ ì˜ë¬¸í˜• ì–´ë¯¸ë¥¼ ì¡°ì‚¬ë¡œ ì˜¤ì¸í•˜ëŠ” ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
""")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ì…ë ¥ (Input)")
    input_val = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš”:", height=600, 
                             placeholder="ì˜ˆ: $a<b$, ì´ë©´... / ëª¨ë‘ ëª‡ ê°œì¸ê°€?")

with col2:
    st.subheader("ê²€ìˆ˜ ë¦¬í¬íŠ¸ (Report)")
    
    if input_val:
        josa_corrector = JosaCorrector()
        temp_text, josa_logs = josa_corrector.run(input_val)
        
        spell_corrector = SpellingCorrector()
        final_text, spell_logs = spell_corrector.run(temp_text)
        
        tab1, tab2 = st.tabs(["ğŸ” ìˆ˜ì‹ ì¡°ì‚¬ ê²€ìˆ˜", "ğŸ“ í•œê¸€/ê¸°í˜¸ ê²€ìˆ˜"])
        
        with tab1:
            if josa_logs:
                st.error(f"ìˆ˜ì‹ ì¡°ì‚¬ ì˜¤ë¥˜: {len(josa_logs)}ê±´")
                df_josa = pd.DataFrame(josa_logs)
                cols = ['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']
                st.dataframe(df_josa[cols], use_container_width=True, hide_index=True)
            else:
                st.success("ìˆ˜ì‹ ì¡°ì‚¬ê°€ ì™„ë²½í•©ë‹ˆë‹¤.")
                
        with tab2:
            if spell_logs:
                st.warning(f"í•œê¸€/ê¸°í˜¸ ì˜¤ë¥˜: {len(spell_logs)}ê±´")
                df_spell = pd.DataFrame(spell_logs)
                cols = ['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']
                st.dataframe(df_spell[cols], use_container_width=True, hide_index=True)
            else:
                st.success("ë°œê²¬ëœ ì˜¤íƒ€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("ìµœì¢… ê²°ê³¼ë¬¼ (Result)")
        st.text_area("êµì •ëœ í…ìŠ¤íŠ¸", value=final_text, height=300)
        
        st.download_button(
            label="ğŸ’¾ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=final_text,
            file_name="corrected_result.txt",
            mime="text/plain"
        )
    else:
        st.info("ì™¼ìª½ì— ë‚´ìš©ì„ ì…ë ¥í•˜ë©´ ìë™ìœ¼ë¡œ ê²€ì‚¬ë¥¼ ì‹œì‘í•©ë‹ˆë‹¤.")