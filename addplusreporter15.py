import streamlit as st
import re
import json
import pandas as pd

# ==========================================
# 1. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘ êµì • í´ëž˜ìŠ¤ (LaTeX ëŒ€ìƒ)
# ==========================================
class JosaCorrector:
    def __init__(self):
        self.log = []
        self.batchim_dict = self._init_batchim_dict()
        self.unit_batchim_dict = self._init_unit_batchim_dict()
        self.particle_pairs = self._init_particle_pairs()
        
        # [ìˆ˜ì‹ ë³´í˜¸] ì¡°ì‚¬ê°€ ì•„ë‹Œ ë‹¨ì–´(ë™ì‚¬/í˜•ìš©ì‚¬ í™œìš©í˜•) ë³´í˜¸ ëª©ë¡
        self.protected_words = [
            'ì´ë‹¤', 'ìž…ë‹ˆë‹¤', 'ì´ë¯€ë¡œ', 'ì´ë©°', 'ì´ê³ ', 'ì´ë‚˜', 'ì´ë©´ì„œ', 'ì´ì§€ë§Œ', 'ì´ì–´ì„œ',
            'ì´ë•Œ', 'ì´ì–´ì•¼', 'ê°€ì§€',
            'ì´ë©´', 
            'ì´ìƒ', 'ì´í•˜', 'ì´ë‚´', 'ì´ì™¸', 'ë¯¸ë§Œ', 'ì´ˆê³¼',
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ìœ¼ë¯€ë¡œ', 'ì´ì–´ì§„', 'ì´ë£¨ì–´ì§„', 'ì´ë£¨ëŠ”', 'ì´ë™', 'ì´ìš©',
            'ì—†ëŠ”', 'ìžˆëŠ”', 'ì—†ê³ ', 'ìžˆê³ ', 'ì—†ì´', 'ìžˆì–´', 'ì—†ì–´',
            # ì§€ì‹œì–´ ë³´í˜¸ íŒ¨í„´
            'ì´ ì ', 'ì´ ì„ ', 'ì´ ê°’', 'ì´ ì‹', 'ì´ ê²½ìš°', 'ì´ ë•Œ', 'ì´ í™•ë¥ ', 'ì´ ì‹œí–‰', 'ì´ ë„í˜•', 'ì´ ë¬¸ì œ',
            'ê·¸ ì ', 'ê·¸ ì„ ', 'ê·¸ ê°’', 'ê·¸ ì‹', 'ê·¸ ê²½ìš°', 'ê·¸ ë•Œ',
            'ì € ì '
        ]

    def _init_batchim_dict(self):
        # ì•ŒíŒŒë²³ ë°œìŒ ê¸°ì¤€ ë°›ì¹¨ ì—¬ë¶€
        # M(ì— ), N(ì—”), L(ì—˜), R(ì•Œ) -> ë°›ì¹¨ ìžˆìŒ (True)
        # ë‚˜ë¨¸ì§€(A, B, C...) -> ë°›ì¹¨ ì—†ìŒ (False)
        d = {
            '0': True, '1': True, '3': True, '6': True, '7': True, '8': True, '10': True,
            'l': True, 'm': True, 'n': True, 'r': True, 
            'L': True, 'M': True, 'N': True, 'R': True, 
            'ì œê³±': True, 'ì—¬ì§‘í•©': True, 'ë°”': False
        }
        for c in "ã„±ã„´ã„·ã„¹ã…ã…‚ã……ã…‡ã…ˆã…Šã…‹ã…Œã…ã…Ž": d[c] = True
        # ë‚˜ë¨¸ì§€ ì•ŒíŒŒë²³ê³¼ ìˆ«ìžëŠ” Falseë¡œ ì´ˆê¸°í™”
        for ch in '2459AaBbCcDdEeFfGgHhIiJjKkOoPpQqSsTtUuVvWwXxeYyZz':
            if ch not in d: d[ch] = False
        return d

    def _init_unit_batchim_dict(self):
        # ë¬¼ë¦¬ ë‹¨ìœ„ ì‚¬ì „ (ì—¬ê¸°ì— ì—†ìœ¼ë©´ ì¼ë°˜ í…ìŠ¤íŠ¸ë¡œ ê°„ì£¼í•˜ì—¬ ë§ˆì§€ë§‰ ê¸€ìžë¡œ íŒë‹¨)
        return {
            'm': False, 'cm': False, 'mm': False, 'km': False,
            'g': True, 'kg': True, 'mg': True,
            'l': False, 'L': False, 'mL': False,
            'A': False, 'V': False, 'W': False, 'Hz': False,
            'deg': False, 'degree': False,
            'N': True  # ë‰´í„´(N) -> ë°›ì¹¨ ìžˆìŒ
        }

    def _init_particle_pairs(self):
        return [
            ('ì´ë‹¤', 'ì´ë‹¤'), ('ìž…ë‹ˆë‹¤', 'ìž…ë‹ˆë‹¤'),
            ('ì´ë¯€ë¡œ', 'ì´ë¯€ë¡œ'), ('ì´ë©°', 'ì´ë©°'), ('ì´ê³ ', 'ì´ê³ '), ('ì´ë‚˜', 'ì´ë‚˜'),
            ('ì´ë©´ì„œ', 'ì´ë©´ì„œ'), ('ì´ì§€ë§Œ', 'ì´ì§€ë§Œ'), ('ì´ì–´ì„œ', 'ì´ì–´ì„œ'),
            ('ì´ë•Œ', 'ì´ë•Œ'), ('ì´ì–´ì•¼ í•˜ë¯€ë¡œ', 'ì´ì–´ì•¼ í•˜ë¯€ë¡œ'),
            ('ê°€ì§€', 'ê°€ì§€'),
            ('ì´ë¼ì„œ', 'ë¼ì„œ'), ('ì´ë¼ê³ ', 'ë¼ê³ '), ('ì´ë¼', 'ë¼'), ('ì´ë©´', 'ë©´'), 
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ'), ('ì„', 'ìš¸')
        ]

    def get_balanced(self, text, start_idx):
        if start_idx == -1 or start_idx >= len(text): return None, start_idx
        count = 0
        for i in range(start_idx, len(text)):
            if text[i] == '{': count += 1
            elif text[i] == '}': count -= 1
            if count == 0: return text[start_idx+1:i], i + 1
        return None, start_idx

    def simplify_formula(self, latex_str):
        current = latex_str.replace(r'\left', '').replace(r'\right', '')
        prev_str = ""
        while prev_str != current:
            prev_str = current
            if '\\frac' in current:
                idx = current.find('\\frac')
                num_start = current.find('{', idx)
                num, end_num = self.get_balanced(current, num_start)
                den_start = current.find('{', end_num)
                _, end_den = self.get_balanced(current, den_start)
                if num is not None:
                    current = current[:idx] + num + current[end_den:]
                    continue
            if '\\sqrt' in current:
                idx = current.find('\\sqrt')
                if idx + 5 < len(current) and current[idx+5] == '[':
                    close_bracket = current.find(']', idx)
                    if close_bracket != -1:
                        current = current[:idx+5] + current[close_bracket+1:]
                        continue
            stripped = current.strip()
            if stripped.startswith('{') and stripped.endswith('}'):
                content, end = self.get_balanced(stripped, 0)
                if end == len(stripped):
                    current = content
                    continue
        return current

    def find_target(self, formula_str):
        simplified = self.simplify_formula(formula_str)
        clean = re.sub(r'\s+', '', simplified)
        
        masked_text = clean
        braces_content = []
        while True:
            start = masked_text.find('{')
            if start == -1: break
            content, end_idx = self.get_balanced(masked_text, start)
            if content is None: break
            placeholder = f"@BRACE{len(braces_content)}@"
            braces_content.append(content)
            masked_text = masked_text[:start] + placeholder + masked_text[end_idx:]

        split_pattern = (r'=|\\approx|\\ne|>|<|\\ge|\\le|\\times|\\div|'
                         r'(?<!\^)\+|(?<!\^)-|\\cdot|'
                         r'\\cap|\\cup|\\setminus|\\subset|\\subseteq|\\in|\\ni')
        parts = re.split(split_pattern, masked_text)
        final_term = parts[-1] if parts else masked_text

        while "@BRACE" in final_term:
            for i, content in enumerate(braces_content):
                placeholder = f"@BRACE{i}@"
                if placeholder in final_term:
                    final_term = final_term.replace(placeholder, "{" + content + "}")

        final_term = final_term.rstrip('\\').strip()

        if r'\degree' in final_term or r'^\circ' in final_term: return "ë„"
        
        if "^" in final_term:
            if "C" in final_term: return "ì—¬ì§‘í•©"
            base_part = final_term.split('^')[0]
            mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', base_part)
            if mathrm_match:
                unit_content = mathrm_match.group(1)
                if unit_content in ['m', 'cm', 'mm', 'km']: return "ë¯¸í„°"
            return "ì œê³±"

        if final_term.endswith(')'):
             m = re.search(r'([ê°€-íž£a-zA-Z0-9])\)+$', final_term)
             if m: return m.group(1)

        mathrm_match = re.search(r'\\mathrm\{([a-zA-Z]+)\}', final_term)
        if mathrm_match: return f"UNIT:{mathrm_match.group(1)}"

        text_only = re.sub(r'\\[a-zA-Z]+|[{}]|[()\[\]]|[\.,]', '', final_term)
        text_only = text_only.replace('\\', '').strip() 
        
        return text_only[-1] if text_only else ""

    def get_correct_p(self, target, original_p):
        for word in self.protected_words:
            if original_p.startswith(word): return original_p

        if not target.startswith("UNIT:") and len(target) == 1 and re.match(r'[a-zA-Z0-9]', target):
            is_noun_mask = False
            if original_p.startswith('ê°€ë©´'):
                after_mask = original_p[2:]
                if after_mask and after_mask[0] in ['ì„', 'ì´', 'ì€', 'ê³¼', 'ì˜', 'ë¡œ']: is_noun_mask = True
                if not is_noun_mask and original_p.startswith(('ì´ë©´', 'ë©´', 'ê°€ë©´')):
                    suffix = original_p[2:] if original_p.startswith('ê°€ë©´') else original_p[len('ì´ë©´' if original_p.startswith('ì´ë©´') else 'ë©´'):]
                    return 'ì´ë©´' + suffix

        has_batchim = False
        if target.startswith("UNIT:"):
            real_unit = target.split(":")[1]
            # â˜… ìˆ˜ì •: ë‹¨ìœ„ ì‚¬ì „ì— ìžˆìœ¼ë©´ ê·¸ ê°’ì„ ë”°ë¥´ê³ , ì—†ìœ¼ë©´(AM ë“±) ë§ˆì§€ë§‰ ê¸€ìžë¡œ íŒë‹¨
            if real_unit in self.unit_batchim_dict:
                has_batchim = self.unit_batchim_dict[real_unit]
            else:
                # ì‚¬ì „ì— ì—†ëŠ” ë‹¨ìœ„(ê¸°í•˜ ì  ë“±)ëŠ” ë§ˆì§€ë§‰ ê¸€ìžì˜ ë°›ì¹¨ ì—¬ë¶€ í™•ì¸
                last_char = real_unit[-1]
                has_batchim = self.batchim_dict.get(last_char, False)
                
        elif target == "ë¯¸í„°": has_batchim = False
        else:
            if target in self.batchim_dict: has_batchim = self.batchim_dict[target]
            elif len(target) == 1 and 'ê°€' <= target <= 'íž£': has_batchim = (ord(target) - 0xAC00) % 28 > 0
            elif len(target) > 1:
                last = target[-1]
                has_batchim = (ord(last) - 0xAC00) % 28 > 0 if 'ê°€' <= last <= 'íž£' else self.batchim_dict.get(last, False)
            else: has_batchim = self.batchim_dict.get(target, False)

        is_rieul = target in ['1', '7', '8', 'L', 'R', 'l', 'r', 'ã„¹']
        
        for has_b, no_b in self.particle_pairs:
            if original_p.startswith(has_b) or original_p.startswith(no_b):
                if has_b == 'ìœ¼ë¡œ':
                    stem = 'ìœ¼ë¡œ' if (has_batchim and not is_rieul) else 'ë¡œ'
                else:
                    stem = has_b if has_batchim else no_b
                return stem + original_p[len(has_b if original_p.startswith(has_b) else no_b):]
        return original_p

    def clean_latex_for_human(self, latex):
        text = re.sub(r'\\(left|right|mathrm|text|bf|it)', '', latex)
        text = text.replace('{', '').replace('}', '').replace('\\', '')
        return text.strip()

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, raw_input):
        self.log = [] 
        try:
            if isinstance(raw_input, dict): input_data = raw_input
            else: input_data = json.loads(raw_input)
            target_text = input_data.get("result", raw_input) if isinstance(input_data, dict) else str(raw_input)
        except:
            target_text = str(raw_input)

        def replacer(match):
            pre, s1, delim, formula, gap, particle = match.groups()
            formula_clean = formula.replace('\\\\', '\\')
            
            p_match = re.search(r'[ê°€-íž£]+', particle)
            match_start = match.start()
            match_end = match.end()

            if not p_match:
                if '.' in particle:
                    new_particle = particle.replace('.', '')
                    human_readable = self.clean_latex_for_human(formula_clean)
                    context = self.get_context(target_text, match_start, match_end)
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": human_readable,
                        "ì›ë¬¸": particle,
                        "ìˆ˜ì •": new_particle,
                        "ì‚¬ìœ ": "ë¶ˆí•„ìš”í•œ ë§ˆì¹¨í‘œ ì œê±°"
                    })
                    return f"{pre}{s1}{delim}{formula}{delim}{gap}{new_particle}"
                return match.group(0)

            p_start = p_match.start()
            original_p = p_match.group()
            remaining_particle = particle[p_start:]
            
            for word in self.protected_words:
                if remaining_particle.startswith(word):
                    return match.group(0)
            
            target = self.find_target(formula_clean)
            correct_p = self.get_correct_p(target, original_p)
            
            if original_p != correct_p:
                human_readable = self.clean_latex_for_human(formula_clean)
                context = self.get_context(target_text, match_start, match_end)
                self.log.append({
                    "ë¬¸ë§¥": context,
                    "ëŒ€ìƒ": human_readable,
                    "ì›ë¬¸": original_p,
                    "ìˆ˜ì •": correct_p,
                    "ì‚¬ìœ ": "ë°›ì¹¨ í˜¸ì‘ ì˜¤ë¥˜"
                })
                return f"{pre}{s1}{delim}{formula}{delim}{gap}{particle[:p_start]}{correct_p}{particle[p_match.end():]}"

            return match.group(0)

        pattern = r'([^$]*?)(\s*)(\$+)([^\$]+)\3((?:[\s,]|(?:\\[a-zA-Z]+)|(?:\\.)|(?:\$(?:(?:\\[a-zA-Z]+)|(?:\\.)|[\s])*\$))*)([ê°€-íž£\s\.\?\!]+)'
        fixed_text = re.sub(pattern, replacer, target_text, flags=re.DOTALL)
        return fixed_text, self.log

# ==========================================
# 2. í•œê¸€ ë§žì¶¤ë²•/ì˜¤íƒ€/ì¡°ì‚¬ êµì • í´ëž˜ìŠ¤
# ==========================================
class SpellingCorrector:
    def __init__(self):
        self.log = []
        self.typo_dict = {
            "ìžë¦¬ìˆ˜": "ìžë¦¿ìˆ˜", "ìµœëŒ€ê°’": "ìµœëŒ“ê°’", "ìµœì†Œê°’": "ìµœì†Ÿê°’", "ê·¹ëŒ€ê°’": "ê·¹ëŒ“ê°’", "ê·¹ì†Œê°’": "ê·¹ì†Ÿê°’",
            "ì ˆëŒ€ê°’": "ì ˆëŒ“ê°’", "ê·¼ì‚¬ê°’": "ê·¼ì‚¿ê°’", "ëŒ€í‘œê°’": "ëŒ€í‘¯ê°’", "í•¨ìˆ˜ê°’": "í•¨ìˆ«ê°’",
            "ê¼­ì§€ì ": "ê¼­ì§“ì ", "ì´›ì ": "ì´ˆì ", "ê°¯ìˆ˜": "ê°œìˆ˜", "ë‚˜ëˆ„ê¸°": "ë‚˜ëˆ—ì…ˆ",
            "ì•Šë˜": "ì•ˆ ë˜", "ì•Šë¼": "ì•ˆ ë¼", "ì•Šëœë‹¤": "ì•ˆ ëœë‹¤", "ë¬¸ì•ˆ": "ë¬´ë‚œ",
            "ê¸ˆìƒˆ": "ê¸ˆì„¸", "ì—­í™œ": "ì—­í• ", "ì œìž‘ë…„": "ìž¬ìž‘ë…„", "ì–´ë–»í•´": "ì–´ë–¡í•´",
            "ëª‡ì¼": "ë©°ì¹ ", "ë“¤ì–´ë‚˜ë‹¤": "ë“œëŸ¬ë‚˜ë‹¤", "ê°€ë¥´í‚¤ë‹¤": "ê°€ë¦¬í‚¤ë‹¤", "ë§žì¶”ë‹¤": "ë§žížˆë‹¤"
        }
        self.korean_particle_pairs = [
            ('ì€', 'ëŠ”'), ('ì´', 'ê°€'), ('ì„', 'ë¥¼'), ('ê³¼', 'ì™€'), ('ìœ¼ë¡œ', 'ë¡œ')
        ]
        
        self.exceptions = {
            'ì¦ê°€', 'ì¶”ê°€', 'ê²°ê³¼', 'íš¨ê³¼', 'ì´ˆê³¼', 'êµê³¼', 'ë¶€ê³¼', 'ì‚¬ê³¼', 'íˆ¬ê³¼',
            'í‰ê°€', 'ì›ê°€', 'ì •ê°€', 'ë‹¨ê°€', 'ì‹œê°€',
            'ì‚¬ì´', 'ì°¨ì´', 'ë‚˜ì´', 'ì•„ì´', 'ì˜¤ì´', 'ë†€ì´',
            'ê²½ë¡œ', 'ì§„ë¡œ', 'ì„ ë¡œ', 'í•­ë¡œ',
            'ì—†ëŠ”', 'ìžˆëŠ”', 'ê°–ëŠ”', 'ë§žëŠ”', 'ë§¡ëŠ”', 'ì›ƒëŠ”', 'ì”»ëŠ”', 'ê¹ŽëŠ”', 'ë³¶ëŠ”', 'ì•ŠëŠ”',
            'ì´ì€', 'ì´ì„', 'ì´ì–´', 'ì´ì–´ì„œ', 'ê¹Šì€', 'ë†’ì€', 'ìž‘ì€', 'ì¢ì€',
            'ì¸ê°€', 'ëŠ”ê°€', 'ì€ê°€', 'ë˜ê°€', 'ë‚˜', 'ê°€' 
        }

    def has_batchim(self, char):
        if 'ê°€' <= char <= 'íž£':
            return (ord(char) - 0xAC00) % 28 > 0
        return False

    def is_rieul_batchim(self, char):
        if 'ê°€' <= char <= 'íž£':
            return (ord(char) - 0xAC00) % 28 == 8
        return False

    def get_context(self, text, start, end, window=10):
        s = max(0, start - window)
        e = min(len(text), end + window)
        context = text[s:e].replace('\n', ' ')
        return f"...{context}..."

    def run(self, text):
        self.log = []
        parts = re.split(r'(\$[^\$]+\$)', text)
        final_parts = []
        
        for i, part in enumerate(parts):
            if i % 2 == 1:
                final_parts.append(part)
                continue
            
            current_text = part
            for wrong, correct in self.typo_dict.items():
                if wrong in current_text:
                    for m in re.finditer(re.escape(wrong), current_text):
                        context = self.get_context(current_text, m.start(), m.end())
                        self.log.append({
                            "ë¬¸ë§¥": context,
                            "ëŒ€ìƒ": wrong,
                            "ì›ë¬¸": wrong,
                            "ìˆ˜ì •": correct,
                            "ì‚¬ìœ ": "ë§žì¶¤ë²•/í‘œì¤€ì–´ ì˜¤ë¥˜"
                        })
                    current_text = current_text.replace(wrong, correct)
            
            pattern = r'([ê°€-íž£ã‰ -ã‰­])(ì€|ëŠ”|ì´|ê°€|ì„|ë¥¼|ê³¼|ì™€|ìœ¼ë¡œ|ë¡œ)(?![ê°€-íž£])'
            
            def josa_replacer(match):
                full_word = match.group(0)
                noun_char = match.group(1)
                josa = match.group(2)
                
                if full_word in self.exceptions:
                    return full_word
                
                if noun_char in ['ì´', 'ê·¸', 'ì €']:
                    return full_word

                if 'ê°€' <= noun_char <= 'íž£':
                    has_bat = self.has_batchim(noun_char)
                    is_rieul = self.is_rieul_batchim(noun_char)
                else: 
                    has_bat = True
                    is_rieul = (noun_char == 'ã‰£')

                correct_josa = josa
                for bat_o, bat_x in self.korean_particle_pairs:
                    if josa == bat_o or josa == bat_x:
                        if bat_o == 'ìœ¼ë¡œ':
                            if not has_bat or is_rieul: correct_josa = 'ë¡œ'
                            else: correct_josa = 'ìœ¼ë¡œ'
                        else:
                            correct_josa = bat_o if has_bat else bat_x
                        break
                
                if josa != correct_josa:
                    context = self.get_context(current_text, match.start(), match.end())
                    self.log.append({
                        "ë¬¸ë§¥": context,
                        "ëŒ€ìƒ": full_word,
                        "ì›ë¬¸": josa,
                        "ìˆ˜ì •": correct_josa,
                        "ì‚¬ìœ ": "ì¡°ì‚¬ í˜¸ì‘ ì˜¤ë¥˜"
                    })
                    return f"{noun_char}{correct_josa}"
                return match.group(0)

            current_text = re.sub(pattern, josa_replacer, current_text)
            final_parts.append(current_text)
            
        return "".join(final_parts), self.log

# ==========================================
# 3. ë©”ì¸ UI (Streamlit)
# ==========================================
st.set_page_config(page_title="ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°", layout="wide")

st.title("âœ¨ ìˆ˜í•™ ë¬¸ì œ í†µí•© êµì •ê¸°")
st.markdown("""
**1. ìˆ˜ì‹ ì¡°ì‚¬ í˜¸ì‘:** LaTeX ìˆ˜ì‹ ë’¤ì˜ ì¡°ì‚¬ë¥¼ êµì •í•©ë‹ˆë‹¤. (ì‰¼í‘œ ë’¤ 'ì´ë©´' ìœ ì§€)  
**2. í•œê¸€ ë§žì¶¤ë²•:** 'ëª‡ ê°œì¸ê°€?' ì²˜ëŸ¼ ì˜ë¬¸í˜• ì–´ë¯¸ë¥¼ ì¡°ì‚¬ë¡œ ì˜¤ì¸í•˜ëŠ” ì˜¤ë¥˜ë¥¼ ìˆ˜ì •í–ˆìŠµë‹ˆë‹¤.
""")

col1, col2 = st.columns([1, 1])

with col1:
    st.subheader("ìž…ë ¥ (Input)")
    input_val = st.text_area("í…ìŠ¤íŠ¸ë¥¼ ìž…ë ¥í•˜ì„¸ìš”:", height=600, 
                             placeholder="ì˜ˆ: $a<b$, ì´ë©´... / ëª¨ë‘ ëª‡ ê°œì¸ê°€?")

with col2:
    st.subheader("ê²€ìˆ˜ ë¦¬í¬íŠ¸ (Report)")
    
    if input_val:
        josa_corrector = JosaCorrector()
        temp_text, josa_logs = josa_corrector.run(input_val)
        
        spell_corrector = SpellingCorrector()
        final_text, spell_logs = spell_corrector.run(temp_text)
        
        tab1, tab2 = st.tabs(["ðŸ” ìˆ˜ì‹ ì¡°ì‚¬ ê²€ìˆ˜", "ðŸ“ í•œê¸€/ê¸°í˜¸ ê²€ìˆ˜"])
        
        with tab1:
            if josa_logs:
                st.error(f"ìˆ˜ì‹ ì¡°ì‚¬ ì˜¤ë¥˜: {len(josa_logs)}ê±´")
                df_josa = pd.DataFrame(josa_logs)
                cols = ['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']
                st.dataframe(df_josa[cols], use_container_width=True, hide_index=True)
            else:
                st.success("ìˆ˜ì‹ ì¡°ì‚¬ê°€ ì™„ë²½í•©ë‹ˆë‹¤.")
                
        with tab2:
            if spell_logs:
                st.warning(f"í•œê¸€/ê¸°í˜¸ ì˜¤ë¥˜: {len(spell_logs)}ê±´")
                df_spell = pd.DataFrame(spell_logs)
                cols = ['ë¬¸ë§¥', 'ëŒ€ìƒ', 'ì›ë¬¸', 'ìˆ˜ì •', 'ì‚¬ìœ ']
                st.dataframe(df_spell[cols], use_container_width=True, hide_index=True)
            else:
                st.success("ë°œê²¬ëœ ì˜¤íƒ€ê°€ ì—†ìŠµë‹ˆë‹¤.")

        st.markdown("---")
        st.subheader("ìµœì¢… ê²°ê³¼ë¬¼ (Result)")
        st.text_area("êµì •ëœ í…ìŠ¤íŠ¸", value=final_text, height=300)
        
        st.download_button(
            label="ðŸ’¾ ê²°ê³¼ íŒŒì¼ ë‹¤ìš´ë¡œë“œ",
            data=final_text,
            file_name="corrected_result.txt",
            mime="text/plain"
        )
    else:
        st.info("ì™¼ìª½ì— ë‚´ìš©ì„ ìž…ë ¥í•˜ë©´ ìžë™ìœ¼ë¡œ ê²€ì‚¬ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤.")